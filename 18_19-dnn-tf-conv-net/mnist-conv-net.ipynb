{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "test_valid_size = 256\n",
    "\n",
    "n_classes = 10\n",
    "dropout = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, w, b, strides=1):\n",
    "    # stride = [batch_stride, height, width, feature_stride]\n",
    "    # best to leave batch and feature @ 1, also Height usually equals width\n",
    "    # for a square stride\n",
    "    \n",
    "    #bias_add is used because the tensors are different shapes, the bias will\n",
    "    #be 1-D and the weights 4-D\n",
    "    \n",
    "    x = tf.nn.conv2d(x, w, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    #does pooling for a kernel(square) of size k and skip every k steps\n",
    "    #kernels are non-overlapping\n",
    "    return tf.nn.max_pool(x, \n",
    "                          ksize=[1, k, k, 1], \n",
    "                          strides=[1, k, k, 1], \n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    #Layer 1 - input: 28x28x1 => 14x14x32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1']) #returns 28x28x32\n",
    "    conv1 = maxpool2d(conv1, k=2) #returns 14x14x32\n",
    "    \n",
    "    #Layer 2 - 14x14x32 to 7x7x64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2']) #14x14x64\n",
    "    conv2 = maxpool2d(conv2, k = 2) #7x7x64\n",
    "    \n",
    "    #reshapes conv2 cube of 7x7x64 to \"vector\" of length 7*7*64 = 3136\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    \n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\\\n",
    ".minimize(cost)\n",
    "    \n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1/429 - Loss 63851.8164 Train Accuracy 0.171875 - Val Accuracy 0.175781\n",
      "Epoch  1, Batch  11/429 - Loss 28516.5625 Train Accuracy 0.273438 - Val Accuracy 0.222656\n",
      "Epoch  1, Batch  21/429 - Loss 17210.3320 Train Accuracy 0.257812 - Val Accuracy 0.335938\n",
      "Epoch  1, Batch  31/429 - Loss 13066.3652 Train Accuracy 0.382812 - Val Accuracy 0.410156\n",
      "Epoch  1, Batch  41/429 - Loss 10234.9160 Train Accuracy 0.406250 - Val Accuracy 0.468750\n",
      "Epoch  1, Batch  51/429 - Loss  8564.0957 Train Accuracy 0.507812 - Val Accuracy 0.500000\n",
      "Epoch  1, Batch  61/429 - Loss  7759.7900 Train Accuracy 0.515625 - Val Accuracy 0.558594\n",
      "Epoch  1, Batch  71/429 - Loss  4711.3623 Train Accuracy 0.593750 - Val Accuracy 0.609375\n",
      "Epoch  1, Batch  81/429 - Loss  4924.7158 Train Accuracy 0.640625 - Val Accuracy 0.640625\n",
      "Epoch  1, Batch  91/429 - Loss  6558.4468 Train Accuracy 0.570312 - Val Accuracy 0.660156\n",
      "Epoch  1, Batch 101/429 - Loss  4780.0781 Train Accuracy 0.687500 - Val Accuracy 0.683594\n",
      "Epoch  1, Batch 111/429 - Loss  4818.9849 Train Accuracy 0.648438 - Val Accuracy 0.679688\n",
      "Epoch  1, Batch 121/429 - Loss  5003.0669 Train Accuracy 0.656250 - Val Accuracy 0.695312\n",
      "Epoch  1, Batch 131/429 - Loss  2938.1919 Train Accuracy 0.695312 - Val Accuracy 0.687500\n",
      "Epoch  1, Batch 141/429 - Loss  2724.3491 Train Accuracy 0.687500 - Val Accuracy 0.718750\n",
      "Epoch  1, Batch 151/429 - Loss  4132.0220 Train Accuracy 0.656250 - Val Accuracy 0.710938\n",
      "Epoch  1, Batch 161/429 - Loss  3380.5916 Train Accuracy 0.750000 - Val Accuracy 0.718750\n",
      "Epoch  1, Batch 171/429 - Loss  2605.2393 Train Accuracy 0.734375 - Val Accuracy 0.746094\n",
      "Epoch  1, Batch 181/429 - Loss  3275.3267 Train Accuracy 0.710938 - Val Accuracy 0.730469\n",
      "Epoch  1, Batch 191/429 - Loss  3635.1855 Train Accuracy 0.710938 - Val Accuracy 0.742188\n",
      "Epoch  1, Batch 201/429 - Loss  3641.6145 Train Accuracy 0.648438 - Val Accuracy 0.742188\n",
      "Epoch  1, Batch 211/429 - Loss  2982.8296 Train Accuracy 0.695312 - Val Accuracy 0.757812\n",
      "Epoch  1, Batch 221/429 - Loss  2384.4475 Train Accuracy 0.757812 - Val Accuracy 0.761719\n",
      "Epoch  1, Batch 231/429 - Loss  1888.8710 Train Accuracy 0.812500 - Val Accuracy 0.757812\n",
      "Epoch  1, Batch 241/429 - Loss  1489.4960 Train Accuracy 0.781250 - Val Accuracy 0.761719\n",
      "Epoch  1, Batch 251/429 - Loss  1804.6321 Train Accuracy 0.742188 - Val Accuracy 0.769531\n",
      "Epoch  1, Batch 261/429 - Loss  2520.2554 Train Accuracy 0.710938 - Val Accuracy 0.765625\n",
      "Epoch  1, Batch 271/429 - Loss  1966.9915 Train Accuracy 0.742188 - Val Accuracy 0.769531\n",
      "Epoch  1, Batch 281/429 - Loss  2072.5195 Train Accuracy 0.789062 - Val Accuracy 0.781250\n",
      "Epoch  1, Batch 291/429 - Loss  2318.9219 Train Accuracy 0.734375 - Val Accuracy 0.765625\n",
      "Epoch  1, Batch 301/429 - Loss  1701.0190 Train Accuracy 0.757812 - Val Accuracy 0.777344\n",
      "Epoch  1, Batch 311/429 - Loss  1667.2617 Train Accuracy 0.765625 - Val Accuracy 0.777344\n",
      "Epoch  1, Batch 321/429 - Loss  1644.5190 Train Accuracy 0.843750 - Val Accuracy 0.777344\n",
      "Epoch  1, Batch 331/429 - Loss  1013.6382 Train Accuracy 0.828125 - Val Accuracy 0.773438\n",
      "Epoch  1, Batch 341/429 - Loss  1765.8942 Train Accuracy 0.781250 - Val Accuracy 0.785156\n",
      "Epoch  1, Batch 351/429 - Loss  1417.5474 Train Accuracy 0.843750 - Val Accuracy 0.773438\n",
      "Epoch  1, Batch 361/429 - Loss  1454.7166 Train Accuracy 0.781250 - Val Accuracy 0.777344\n",
      "Epoch  1, Batch 371/429 - Loss  1703.0582 Train Accuracy 0.726562 - Val Accuracy 0.781250\n",
      "Epoch  1, Batch 381/429 - Loss  1335.4307 Train Accuracy 0.796875 - Val Accuracy 0.785156\n",
      "Epoch  1, Batch 391/429 - Loss  1465.0492 Train Accuracy 0.804688 - Val Accuracy 0.765625\n",
      "Epoch  1, Batch 401/429 - Loss  1829.1963 Train Accuracy 0.750000 - Val Accuracy 0.777344\n",
      "Epoch  1, Batch 411/429 - Loss  1010.4175 Train Accuracy 0.812500 - Val Accuracy 0.781250\n",
      "Epoch  1, Batch 421/429 - Loss  2012.8699 Train Accuracy 0.781250 - Val Accuracy 0.789062\n",
      "Epoch  2, Batch   1/429 - Loss  1617.3911 Train Accuracy 0.757812 - Val Accuracy 0.781250\n",
      "Epoch  2, Batch  11/429 - Loss  1320.3711 Train Accuracy 0.796875 - Val Accuracy 0.781250\n",
      "Epoch  2, Batch  21/429 - Loss  1437.3857 Train Accuracy 0.773438 - Val Accuracy 0.781250\n",
      "Epoch  2, Batch  31/429 - Loss  1234.4861 Train Accuracy 0.781250 - Val Accuracy 0.777344\n",
      "Epoch  2, Batch  41/429 - Loss  1275.4739 Train Accuracy 0.781250 - Val Accuracy 0.781250\n",
      "Epoch  2, Batch  51/429 - Loss  1448.9845 Train Accuracy 0.804688 - Val Accuracy 0.789062\n",
      "Epoch  2, Batch  61/429 - Loss  1558.7969 Train Accuracy 0.796875 - Val Accuracy 0.785156\n",
      "Epoch  2, Batch  71/429 - Loss  1465.7354 Train Accuracy 0.812500 - Val Accuracy 0.781250\n",
      "Epoch  2, Batch  81/429 - Loss  1757.9679 Train Accuracy 0.757812 - Val Accuracy 0.796875\n",
      "Epoch  2, Batch  91/429 - Loss  1449.6550 Train Accuracy 0.789062 - Val Accuracy 0.785156\n",
      "Epoch  2, Batch 101/429 - Loss  1773.7390 Train Accuracy 0.757812 - Val Accuracy 0.785156\n",
      "Epoch  2, Batch 111/429 - Loss  1489.7620 Train Accuracy 0.820312 - Val Accuracy 0.792969\n",
      "Epoch  2, Batch 121/429 - Loss  1371.4174 Train Accuracy 0.765625 - Val Accuracy 0.800781\n",
      "Epoch  2, Batch 131/429 - Loss  1224.0519 Train Accuracy 0.804688 - Val Accuracy 0.792969\n",
      "Epoch  2, Batch 141/429 - Loss  1442.3068 Train Accuracy 0.750000 - Val Accuracy 0.789062\n",
      "Epoch  2, Batch 151/429 - Loss  1454.2020 Train Accuracy 0.820312 - Val Accuracy 0.796875\n",
      "Epoch  2, Batch 161/429 - Loss  1681.1011 Train Accuracy 0.750000 - Val Accuracy 0.792969\n",
      "Epoch  2, Batch 171/429 - Loss  1082.2921 Train Accuracy 0.843750 - Val Accuracy 0.812500\n",
      "Epoch  2, Batch 181/429 - Loss  1364.6794 Train Accuracy 0.796875 - Val Accuracy 0.800781\n",
      "Epoch  2, Batch 191/429 - Loss  1061.5686 Train Accuracy 0.859375 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 201/429 - Loss  1403.4812 Train Accuracy 0.765625 - Val Accuracy 0.812500\n",
      "Epoch  2, Batch 211/429 - Loss  1152.2935 Train Accuracy 0.773438 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 221/429 - Loss   794.0943 Train Accuracy 0.859375 - Val Accuracy 0.808594\n",
      "Epoch  2, Batch 231/429 - Loss   706.9713 Train Accuracy 0.804688 - Val Accuracy 0.800781\n",
      "Epoch  2, Batch 241/429 - Loss   961.8234 Train Accuracy 0.851562 - Val Accuracy 0.800781\n",
      "Epoch  2, Batch 251/429 - Loss   933.2556 Train Accuracy 0.820312 - Val Accuracy 0.800781\n",
      "Epoch  2, Batch 261/429 - Loss  1089.2672 Train Accuracy 0.812500 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 271/429 - Loss  1244.2249 Train Accuracy 0.804688 - Val Accuracy 0.796875\n",
      "Epoch  2, Batch 281/429 - Loss  1225.8601 Train Accuracy 0.789062 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 291/429 - Loss  1160.2578 Train Accuracy 0.773438 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 301/429 - Loss   817.7524 Train Accuracy 0.796875 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 311/429 - Loss   640.6880 Train Accuracy 0.859375 - Val Accuracy 0.800781\n",
      "Epoch  2, Batch 321/429 - Loss   833.1788 Train Accuracy 0.851562 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 331/429 - Loss  1241.9519 Train Accuracy 0.804688 - Val Accuracy 0.800781\n",
      "Epoch  2, Batch 341/429 - Loss   533.3950 Train Accuracy 0.859375 - Val Accuracy 0.808594\n",
      "Epoch  2, Batch 351/429 - Loss  1126.5063 Train Accuracy 0.789062 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 361/429 - Loss  1055.8276 Train Accuracy 0.820312 - Val Accuracy 0.816406\n",
      "Epoch  2, Batch 371/429 - Loss   883.2430 Train Accuracy 0.820312 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 381/429 - Loss   795.8262 Train Accuracy 0.804688 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 391/429 - Loss  1048.1665 Train Accuracy 0.828125 - Val Accuracy 0.796875\n",
      "Epoch  2, Batch 401/429 - Loss  1313.8835 Train Accuracy 0.765625 - Val Accuracy 0.808594\n",
      "Epoch  2, Batch 411/429 - Loss   823.6909 Train Accuracy 0.820312 - Val Accuracy 0.804688\n",
      "Epoch  2, Batch 421/429 - Loss   910.3591 Train Accuracy 0.820312 - Val Accuracy 0.812500\n",
      "Epoch  3, Batch   1/429 - Loss   800.1852 Train Accuracy 0.812500 - Val Accuracy 0.804688\n",
      "Epoch  3, Batch  11/429 - Loss   885.1152 Train Accuracy 0.804688 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch  21/429 - Loss   981.3215 Train Accuracy 0.828125 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch  31/429 - Loss   635.3041 Train Accuracy 0.828125 - Val Accuracy 0.816406\n",
      "Epoch  3, Batch  41/429 - Loss   941.5374 Train Accuracy 0.750000 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch  51/429 - Loss   765.2131 Train Accuracy 0.875000 - Val Accuracy 0.828125\n",
      "Epoch  3, Batch  61/429 - Loss   589.4733 Train Accuracy 0.843750 - Val Accuracy 0.828125\n",
      "Epoch  3, Batch  71/429 - Loss   674.9294 Train Accuracy 0.828125 - Val Accuracy 0.824219\n",
      "Epoch  3, Batch  81/429 - Loss   930.0687 Train Accuracy 0.835938 - Val Accuracy 0.824219\n",
      "Epoch  3, Batch  91/429 - Loss   889.1952 Train Accuracy 0.843750 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 101/429 - Loss  1030.6930 Train Accuracy 0.789062 - Val Accuracy 0.824219\n",
      "Epoch  3, Batch 111/429 - Loss   587.3814 Train Accuracy 0.875000 - Val Accuracy 0.828125\n",
      "Epoch  3, Batch 121/429 - Loss   775.4166 Train Accuracy 0.804688 - Val Accuracy 0.824219\n",
      "Epoch  3, Batch 131/429 - Loss   886.6112 Train Accuracy 0.828125 - Val Accuracy 0.832031\n",
      "Epoch  3, Batch 141/429 - Loss   794.1956 Train Accuracy 0.843750 - Val Accuracy 0.828125\n",
      "Epoch  3, Batch 151/429 - Loss   939.9801 Train Accuracy 0.812500 - Val Accuracy 0.824219\n",
      "Epoch  3, Batch 161/429 - Loss   666.0856 Train Accuracy 0.835938 - Val Accuracy 0.832031\n",
      "Epoch  3, Batch 171/429 - Loss   538.8665 Train Accuracy 0.882812 - Val Accuracy 0.828125\n",
      "Epoch  3, Batch 181/429 - Loss   942.7564 Train Accuracy 0.789062 - Val Accuracy 0.828125\n",
      "Epoch  3, Batch 191/429 - Loss   927.0876 Train Accuracy 0.804688 - Val Accuracy 0.828125\n",
      "Epoch  3, Batch 201/429 - Loss  1123.9810 Train Accuracy 0.789062 - Val Accuracy 0.824219\n",
      "Epoch  3, Batch 211/429 - Loss   799.8142 Train Accuracy 0.820312 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 221/429 - Loss   531.1884 Train Accuracy 0.875000 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 231/429 - Loss   457.0298 Train Accuracy 0.843750 - Val Accuracy 0.816406\n",
      "Epoch  3, Batch 241/429 - Loss   663.8362 Train Accuracy 0.828125 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 251/429 - Loss   821.1151 Train Accuracy 0.812500 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 261/429 - Loss   621.0635 Train Accuracy 0.875000 - Val Accuracy 0.816406\n",
      "Epoch  3, Batch 271/429 - Loss   840.5289 Train Accuracy 0.804688 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 281/429 - Loss   927.0125 Train Accuracy 0.812500 - Val Accuracy 0.816406\n",
      "Epoch  3, Batch 291/429 - Loss   797.3522 Train Accuracy 0.796875 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 301/429 - Loss   325.4203 Train Accuracy 0.867188 - Val Accuracy 0.816406\n",
      "Epoch  3, Batch 311/429 - Loss   310.2574 Train Accuracy 0.867188 - Val Accuracy 0.812500\n",
      "Epoch  3, Batch 321/429 - Loss   464.5640 Train Accuracy 0.898438 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 331/429 - Loss   684.5912 Train Accuracy 0.820312 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 341/429 - Loss   497.1265 Train Accuracy 0.875000 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 351/429 - Loss   474.3664 Train Accuracy 0.890625 - Val Accuracy 0.820312\n",
      "Epoch  3, Batch 361/429 - Loss   505.9008 Train Accuracy 0.835938 - Val Accuracy 0.828125\n",
      "Epoch  3, Batch 371/429 - Loss   679.4631 Train Accuracy 0.828125 - Val Accuracy 0.828125\n",
      "Epoch  3, Batch 381/429 - Loss   596.2982 Train Accuracy 0.843750 - Val Accuracy 0.832031\n",
      "Epoch  3, Batch 391/429 - Loss   729.4985 Train Accuracy 0.781250 - Val Accuracy 0.824219\n",
      "Epoch  3, Batch 401/429 - Loss   671.2421 Train Accuracy 0.851562 - Val Accuracy 0.824219\n",
      "Epoch  3, Batch 411/429 - Loss   565.8967 Train Accuracy 0.796875 - Val Accuracy 0.824219\n",
      "Epoch  3, Batch 421/429 - Loss   814.5912 Train Accuracy 0.820312 - Val Accuracy 0.828125\n",
      "Epoch  4, Batch   1/429 - Loss   438.6732 Train Accuracy 0.851562 - Val Accuracy 0.832031\n",
      "Epoch  4, Batch  11/429 - Loss   591.8770 Train Accuracy 0.828125 - Val Accuracy 0.835938\n",
      "Epoch  4, Batch  21/429 - Loss   836.2864 Train Accuracy 0.835938 - Val Accuracy 0.835938\n",
      "Epoch  4, Batch  31/429 - Loss   443.4075 Train Accuracy 0.882812 - Val Accuracy 0.835938\n",
      "Epoch  4, Batch  41/429 - Loss   524.6326 Train Accuracy 0.835938 - Val Accuracy 0.832031\n",
      "Epoch  4, Batch  51/429 - Loss   324.1542 Train Accuracy 0.882812 - Val Accuracy 0.828125\n",
      "Epoch  4, Batch  61/429 - Loss   627.5049 Train Accuracy 0.828125 - Val Accuracy 0.828125\n",
      "Epoch  4, Batch  71/429 - Loss   585.0991 Train Accuracy 0.835938 - Val Accuracy 0.835938\n",
      "Epoch  4, Batch  81/429 - Loss   662.0969 Train Accuracy 0.828125 - Val Accuracy 0.828125\n",
      "Epoch  4, Batch  91/429 - Loss   649.2695 Train Accuracy 0.867188 - Val Accuracy 0.828125\n",
      "Epoch  4, Batch 101/429 - Loss   573.9811 Train Accuracy 0.843750 - Val Accuracy 0.828125\n",
      "Epoch  4, Batch 111/429 - Loss   446.4516 Train Accuracy 0.882812 - Val Accuracy 0.835938\n",
      "Epoch  4, Batch 121/429 - Loss   656.6919 Train Accuracy 0.820312 - Val Accuracy 0.835938\n",
      "Epoch  4, Batch 131/429 - Loss   610.7091 Train Accuracy 0.820312 - Val Accuracy 0.832031\n",
      "Epoch  4, Batch 141/429 - Loss   772.2239 Train Accuracy 0.781250 - Val Accuracy 0.832031\n",
      "Epoch  4, Batch 151/429 - Loss   931.8324 Train Accuracy 0.781250 - Val Accuracy 0.839844\n",
      "Epoch  4, Batch 161/429 - Loss   462.3779 Train Accuracy 0.859375 - Val Accuracy 0.843750\n",
      "Epoch  4, Batch 171/429 - Loss   465.1543 Train Accuracy 0.898438 - Val Accuracy 0.828125\n",
      "Epoch  4, Batch 181/429 - Loss   727.0282 Train Accuracy 0.812500 - Val Accuracy 0.843750\n",
      "Epoch  4, Batch 191/429 - Loss   487.1553 Train Accuracy 0.835938 - Val Accuracy 0.843750\n",
      "Epoch  4, Batch 201/429 - Loss   522.5953 Train Accuracy 0.804688 - Val Accuracy 0.839844\n",
      "Epoch  4, Batch 211/429 - Loss   620.7739 Train Accuracy 0.843750 - Val Accuracy 0.843750\n",
      "Epoch  4, Batch 221/429 - Loss   257.3726 Train Accuracy 0.898438 - Val Accuracy 0.839844\n",
      "Epoch  4, Batch 231/429 - Loss   765.2860 Train Accuracy 0.843750 - Val Accuracy 0.847656\n",
      "Epoch  4, Batch 241/429 - Loss   509.3763 Train Accuracy 0.859375 - Val Accuracy 0.851562\n",
      "Epoch  4, Batch 251/429 - Loss   270.1636 Train Accuracy 0.898438 - Val Accuracy 0.847656\n",
      "Epoch  4, Batch 261/429 - Loss   540.7440 Train Accuracy 0.843750 - Val Accuracy 0.843750\n",
      "Epoch  4, Batch 271/429 - Loss   856.2103 Train Accuracy 0.789062 - Val Accuracy 0.835938\n",
      "Epoch  4, Batch 281/429 - Loss   366.2819 Train Accuracy 0.820312 - Val Accuracy 0.832031\n",
      "Epoch  4, Batch 291/429 - Loss   525.2146 Train Accuracy 0.875000 - Val Accuracy 0.839844\n",
      "Epoch  4, Batch 301/429 - Loss   551.1907 Train Accuracy 0.835938 - Val Accuracy 0.843750\n",
      "Epoch  4, Batch 311/429 - Loss   472.2376 Train Accuracy 0.843750 - Val Accuracy 0.847656\n",
      "Epoch  4, Batch 321/429 - Loss   668.7177 Train Accuracy 0.812500 - Val Accuracy 0.839844\n",
      "Epoch  4, Batch 331/429 - Loss   636.9636 Train Accuracy 0.828125 - Val Accuracy 0.847656\n",
      "Epoch  4, Batch 341/429 - Loss   779.9852 Train Accuracy 0.812500 - Val Accuracy 0.843750\n",
      "Epoch  4, Batch 351/429 - Loss   681.3457 Train Accuracy 0.828125 - Val Accuracy 0.847656\n",
      "Epoch  4, Batch 361/429 - Loss   772.2646 Train Accuracy 0.789062 - Val Accuracy 0.847656\n",
      "Epoch  4, Batch 371/429 - Loss   521.7494 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  4, Batch 381/429 - Loss   533.5872 Train Accuracy 0.828125 - Val Accuracy 0.847656\n",
      "Epoch  4, Batch 391/429 - Loss   510.6927 Train Accuracy 0.835938 - Val Accuracy 0.847656\n",
      "Epoch  4, Batch 401/429 - Loss   285.1229 Train Accuracy 0.890625 - Val Accuracy 0.847656\n",
      "Epoch  4, Batch 411/429 - Loss   476.9776 Train Accuracy 0.843750 - Val Accuracy 0.851562\n",
      "Epoch  4, Batch 421/429 - Loss   521.9550 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch   1/429 - Loss   552.3989 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch  11/429 - Loss   514.0823 Train Accuracy 0.843750 - Val Accuracy 0.859375\n",
      "Epoch  5, Batch  21/429 - Loss   692.4249 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch  31/429 - Loss   476.3799 Train Accuracy 0.851562 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch  41/429 - Loss   613.0454 Train Accuracy 0.843750 - Val Accuracy 0.843750\n",
      "Epoch  5, Batch  51/429 - Loss   707.4791 Train Accuracy 0.796875 - Val Accuracy 0.847656\n",
      "Epoch  5, Batch  61/429 - Loss   465.3221 Train Accuracy 0.859375 - Val Accuracy 0.855469\n",
      "Epoch  5, Batch  71/429 - Loss   568.8934 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch  81/429 - Loss   374.4300 Train Accuracy 0.859375 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch  91/429 - Loss   668.3321 Train Accuracy 0.875000 - Val Accuracy 0.847656\n",
      "Epoch  5, Batch 101/429 - Loss   334.1069 Train Accuracy 0.867188 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch 111/429 - Loss   386.7702 Train Accuracy 0.851562 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch 121/429 - Loss   386.5883 Train Accuracy 0.867188 - Val Accuracy 0.847656\n",
      "Epoch  5, Batch 131/429 - Loss   299.1847 Train Accuracy 0.859375 - Val Accuracy 0.847656\n",
      "Epoch  5, Batch 141/429 - Loss   574.0240 Train Accuracy 0.843750 - Val Accuracy 0.847656\n",
      "Epoch  5, Batch 151/429 - Loss   554.0402 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch 161/429 - Loss   563.7335 Train Accuracy 0.812500 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch 171/429 - Loss   635.4266 Train Accuracy 0.820312 - Val Accuracy 0.867188\n",
      "Epoch  5, Batch 181/429 - Loss   412.8416 Train Accuracy 0.843750 - Val Accuracy 0.863281\n",
      "Epoch  5, Batch 191/429 - Loss  1020.3884 Train Accuracy 0.812500 - Val Accuracy 0.863281\n",
      "Epoch  5, Batch 201/429 - Loss   380.9222 Train Accuracy 0.835938 - Val Accuracy 0.859375\n",
      "Epoch  5, Batch 211/429 - Loss   422.8760 Train Accuracy 0.859375 - Val Accuracy 0.859375\n",
      "Epoch  5, Batch 221/429 - Loss   451.3182 Train Accuracy 0.835938 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch 231/429 - Loss   459.6231 Train Accuracy 0.812500 - Val Accuracy 0.855469\n",
      "Epoch  5, Batch 241/429 - Loss   373.7657 Train Accuracy 0.851562 - Val Accuracy 0.855469\n",
      "Epoch  5, Batch 251/429 - Loss   572.6022 Train Accuracy 0.835938 - Val Accuracy 0.855469\n",
      "Epoch  5, Batch 261/429 - Loss   659.0400 Train Accuracy 0.835938 - Val Accuracy 0.847656\n",
      "Epoch  5, Batch 271/429 - Loss   461.9537 Train Accuracy 0.835938 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch 281/429 - Loss   484.3694 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch 291/429 - Loss   412.1476 Train Accuracy 0.843750 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch 301/429 - Loss   336.9682 Train Accuracy 0.859375 - Val Accuracy 0.839844\n",
      "Epoch  5, Batch 311/429 - Loss   796.9773 Train Accuracy 0.796875 - Val Accuracy 0.839844\n",
      "Epoch  5, Batch 321/429 - Loss   766.7772 Train Accuracy 0.789062 - Val Accuracy 0.843750\n",
      "Epoch  5, Batch 331/429 - Loss   430.1880 Train Accuracy 0.859375 - Val Accuracy 0.851562\n",
      "Epoch  5, Batch 341/429 - Loss   288.4059 Train Accuracy 0.890625 - Val Accuracy 0.847656\n",
      "Epoch  5, Batch 351/429 - Loss   623.9744 Train Accuracy 0.812500 - Val Accuracy 0.839844\n",
      "Epoch  5, Batch 361/429 - Loss   351.6275 Train Accuracy 0.890625 - Val Accuracy 0.843750\n",
      "Epoch  5, Batch 371/429 - Loss   539.3795 Train Accuracy 0.812500 - Val Accuracy 0.847656\n",
      "Epoch  5, Batch 381/429 - Loss   529.0507 Train Accuracy 0.851562 - Val Accuracy 0.847656\n",
      "Epoch  5, Batch 391/429 - Loss   406.3163 Train Accuracy 0.843750 - Val Accuracy 0.843750\n",
      "Epoch  5, Batch 401/429 - Loss   404.0470 Train Accuracy 0.859375 - Val Accuracy 0.843750\n",
      "Epoch  5, Batch 411/429 - Loss   281.3725 Train Accuracy 0.882812 - Val Accuracy 0.843750\n",
      "Epoch  5, Batch 421/429 - Loss   604.5305 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch   1/429 - Loss   469.7948 Train Accuracy 0.828125 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch  11/429 - Loss   632.2999 Train Accuracy 0.820312 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch  21/429 - Loss   372.2009 Train Accuracy 0.835938 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch  31/429 - Loss   362.1291 Train Accuracy 0.875000 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch  41/429 - Loss   750.3085 Train Accuracy 0.804688 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch  51/429 - Loss   470.0428 Train Accuracy 0.820312 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch  61/429 - Loss   537.9963 Train Accuracy 0.859375 - Val Accuracy 0.843750\n",
      "Epoch  6, Batch  71/429 - Loss   386.9097 Train Accuracy 0.875000 - Val Accuracy 0.843750\n",
      "Epoch  6, Batch  81/429 - Loss   458.7628 Train Accuracy 0.882812 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch  91/429 - Loss   452.2285 Train Accuracy 0.843750 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch 101/429 - Loss   446.8241 Train Accuracy 0.835938 - Val Accuracy 0.863281\n",
      "Epoch  6, Batch 111/429 - Loss   576.9375 Train Accuracy 0.843750 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch 121/429 - Loss   748.7592 Train Accuracy 0.781250 - Val Accuracy 0.839844\n",
      "Epoch  6, Batch 131/429 - Loss   551.0929 Train Accuracy 0.843750 - Val Accuracy 0.839844\n",
      "Epoch  6, Batch 141/429 - Loss   280.9866 Train Accuracy 0.882812 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch 151/429 - Loss   549.9979 Train Accuracy 0.812500 - Val Accuracy 0.855469\n",
      "Epoch  6, Batch 161/429 - Loss   311.4438 Train Accuracy 0.851562 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch 171/429 - Loss   521.9595 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch 181/429 - Loss   339.0671 Train Accuracy 0.882812 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch 191/429 - Loss   415.3597 Train Accuracy 0.828125 - Val Accuracy 0.855469\n",
      "Epoch  6, Batch 201/429 - Loss   380.4326 Train Accuracy 0.851562 - Val Accuracy 0.843750\n",
      "Epoch  6, Batch 211/429 - Loss   384.3518 Train Accuracy 0.835938 - Val Accuracy 0.843750\n",
      "Epoch  6, Batch 221/429 - Loss   544.4440 Train Accuracy 0.851562 - Val Accuracy 0.839844\n",
      "Epoch  6, Batch 231/429 - Loss   126.1841 Train Accuracy 0.921875 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch 241/429 - Loss   353.8944 Train Accuracy 0.867188 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch 251/429 - Loss   358.8042 Train Accuracy 0.890625 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch 261/429 - Loss   486.9050 Train Accuracy 0.820312 - Val Accuracy 0.843750\n",
      "Epoch  6, Batch 271/429 - Loss   218.9462 Train Accuracy 0.867188 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch 281/429 - Loss   343.4411 Train Accuracy 0.875000 - Val Accuracy 0.855469\n",
      "Epoch  6, Batch 291/429 - Loss   423.2900 Train Accuracy 0.828125 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch 301/429 - Loss   403.7456 Train Accuracy 0.859375 - Val Accuracy 0.843750\n",
      "Epoch  6, Batch 311/429 - Loss   312.9984 Train Accuracy 0.843750 - Val Accuracy 0.839844\n",
      "Epoch  6, Batch 321/429 - Loss   277.5821 Train Accuracy 0.875000 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch 331/429 - Loss   514.0045 Train Accuracy 0.796875 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch 341/429 - Loss   446.2831 Train Accuracy 0.867188 - Val Accuracy 0.847656\n",
      "Epoch  6, Batch 351/429 - Loss   551.6365 Train Accuracy 0.773438 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch 361/429 - Loss   333.5013 Train Accuracy 0.867188 - Val Accuracy 0.863281\n",
      "Epoch  6, Batch 371/429 - Loss   393.8245 Train Accuracy 0.867188 - Val Accuracy 0.843750\n",
      "Epoch  6, Batch 381/429 - Loss   380.9470 Train Accuracy 0.812500 - Val Accuracy 0.851562\n",
      "Epoch  6, Batch 391/429 - Loss   460.9887 Train Accuracy 0.843750 - Val Accuracy 0.859375\n",
      "Epoch  6, Batch 401/429 - Loss   210.7871 Train Accuracy 0.875000 - Val Accuracy 0.855469\n",
      "Epoch  6, Batch 411/429 - Loss   273.0461 Train Accuracy 0.859375 - Val Accuracy 0.855469\n",
      "Epoch  6, Batch 421/429 - Loss   610.0864 Train Accuracy 0.820312 - Val Accuracy 0.855469\n",
      "Epoch  7, Batch   1/429 - Loss   482.5157 Train Accuracy 0.820312 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch  11/429 - Loss   314.6537 Train Accuracy 0.859375 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch  21/429 - Loss   476.3875 Train Accuracy 0.820312 - Val Accuracy 0.855469\n",
      "Epoch  7, Batch  31/429 - Loss   373.4352 Train Accuracy 0.875000 - Val Accuracy 0.855469\n",
      "Epoch  7, Batch  41/429 - Loss   381.4694 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch  51/429 - Loss   589.3900 Train Accuracy 0.781250 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch  61/429 - Loss   436.9692 Train Accuracy 0.851562 - Val Accuracy 0.843750\n",
      "Epoch  7, Batch  71/429 - Loss   461.7322 Train Accuracy 0.789062 - Val Accuracy 0.859375\n",
      "Epoch  7, Batch  81/429 - Loss   495.1878 Train Accuracy 0.804688 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch  91/429 - Loss   426.2457 Train Accuracy 0.875000 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 101/429 - Loss   414.5117 Train Accuracy 0.851562 - Val Accuracy 0.855469\n",
      "Epoch  7, Batch 111/429 - Loss   348.5897 Train Accuracy 0.828125 - Val Accuracy 0.855469\n",
      "Epoch  7, Batch 121/429 - Loss   633.5668 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 131/429 - Loss   424.3389 Train Accuracy 0.828125 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 141/429 - Loss   356.2479 Train Accuracy 0.820312 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 151/429 - Loss   411.6937 Train Accuracy 0.835938 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 161/429 - Loss   284.2241 Train Accuracy 0.882812 - Val Accuracy 0.855469\n",
      "Epoch  7, Batch 171/429 - Loss   374.3842 Train Accuracy 0.820312 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 181/429 - Loss   441.4815 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 191/429 - Loss   296.2986 Train Accuracy 0.867188 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 201/429 - Loss   388.4800 Train Accuracy 0.875000 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 211/429 - Loss   460.3618 Train Accuracy 0.828125 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 221/429 - Loss   317.0224 Train Accuracy 0.867188 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 231/429 - Loss   289.1190 Train Accuracy 0.875000 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 241/429 - Loss   535.9442 Train Accuracy 0.796875 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 251/429 - Loss   310.0979 Train Accuracy 0.828125 - Val Accuracy 0.859375\n",
      "Epoch  7, Batch 261/429 - Loss   273.9519 Train Accuracy 0.875000 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 271/429 - Loss   535.1366 Train Accuracy 0.812500 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 281/429 - Loss   188.2396 Train Accuracy 0.867188 - Val Accuracy 0.867188\n",
      "Epoch  7, Batch 291/429 - Loss   319.2944 Train Accuracy 0.875000 - Val Accuracy 0.859375\n",
      "Epoch  7, Batch 301/429 - Loss   209.8824 Train Accuracy 0.859375 - Val Accuracy 0.859375\n",
      "Epoch  7, Batch 311/429 - Loss   466.4131 Train Accuracy 0.804688 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 321/429 - Loss   226.4491 Train Accuracy 0.867188 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 331/429 - Loss   551.2358 Train Accuracy 0.781250 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 341/429 - Loss   368.9451 Train Accuracy 0.867188 - Val Accuracy 0.843750\n",
      "Epoch  7, Batch 351/429 - Loss   348.0071 Train Accuracy 0.796875 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 361/429 - Loss   137.6623 Train Accuracy 0.906250 - Val Accuracy 0.855469\n",
      "Epoch  7, Batch 371/429 - Loss   332.9462 Train Accuracy 0.859375 - Val Accuracy 0.847656\n",
      "Epoch  7, Batch 381/429 - Loss   257.6218 Train Accuracy 0.882812 - Val Accuracy 0.855469\n",
      "Epoch  7, Batch 391/429 - Loss   231.9542 Train Accuracy 0.859375 - Val Accuracy 0.859375\n",
      "Epoch  7, Batch 401/429 - Loss   335.0767 Train Accuracy 0.843750 - Val Accuracy 0.855469\n",
      "Epoch  7, Batch 411/429 - Loss   174.9329 Train Accuracy 0.882812 - Val Accuracy 0.851562\n",
      "Epoch  7, Batch 421/429 - Loss   362.2114 Train Accuracy 0.835938 - Val Accuracy 0.847656\n",
      "Epoch  8, Batch   1/429 - Loss   283.5539 Train Accuracy 0.843750 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch  11/429 - Loss   388.7153 Train Accuracy 0.812500 - Val Accuracy 0.847656\n",
      "Epoch  8, Batch  21/429 - Loss   415.1343 Train Accuracy 0.828125 - Val Accuracy 0.843750\n",
      "Epoch  8, Batch  31/429 - Loss   231.8800 Train Accuracy 0.867188 - Val Accuracy 0.843750\n",
      "Epoch  8, Batch  41/429 - Loss   356.1273 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch  51/429 - Loss   239.4544 Train Accuracy 0.882812 - Val Accuracy 0.839844\n",
      "Epoch  8, Batch  61/429 - Loss   294.6446 Train Accuracy 0.867188 - Val Accuracy 0.847656\n",
      "Epoch  8, Batch  71/429 - Loss   256.5782 Train Accuracy 0.882812 - Val Accuracy 0.843750\n",
      "Epoch  8, Batch  81/429 - Loss   288.5538 Train Accuracy 0.828125 - Val Accuracy 0.847656\n",
      "Epoch  8, Batch  91/429 - Loss   371.2675 Train Accuracy 0.812500 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 101/429 - Loss   282.3675 Train Accuracy 0.867188 - Val Accuracy 0.847656\n",
      "Epoch  8, Batch 111/429 - Loss   403.7277 Train Accuracy 0.820312 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 121/429 - Loss   387.3775 Train Accuracy 0.843750 - Val Accuracy 0.859375\n",
      "Epoch  8, Batch 131/429 - Loss   335.6913 Train Accuracy 0.851562 - Val Accuracy 0.863281\n",
      "Epoch  8, Batch 141/429 - Loss   254.0513 Train Accuracy 0.820312 - Val Accuracy 0.859375\n",
      "Epoch  8, Batch 151/429 - Loss   308.1687 Train Accuracy 0.898438 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 161/429 - Loss   303.8848 Train Accuracy 0.859375 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 171/429 - Loss   361.3033 Train Accuracy 0.835938 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 181/429 - Loss   317.8048 Train Accuracy 0.859375 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 191/429 - Loss   326.0627 Train Accuracy 0.859375 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 201/429 - Loss   295.3146 Train Accuracy 0.882812 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 211/429 - Loss   470.9553 Train Accuracy 0.781250 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 221/429 - Loss   434.3661 Train Accuracy 0.804688 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 231/429 - Loss   501.8575 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 241/429 - Loss   453.5405 Train Accuracy 0.820312 - Val Accuracy 0.847656\n",
      "Epoch  8, Batch 251/429 - Loss   379.3514 Train Accuracy 0.859375 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 261/429 - Loss   469.5422 Train Accuracy 0.843750 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 271/429 - Loss   283.5785 Train Accuracy 0.828125 - Val Accuracy 0.859375\n",
      "Epoch  8, Batch 281/429 - Loss   309.5369 Train Accuracy 0.828125 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 291/429 - Loss   215.6827 Train Accuracy 0.875000 - Val Accuracy 0.847656\n",
      "Epoch  8, Batch 301/429 - Loss   215.6735 Train Accuracy 0.875000 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 311/429 - Loss   385.5660 Train Accuracy 0.835938 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 321/429 - Loss   370.1487 Train Accuracy 0.820312 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 331/429 - Loss   228.3921 Train Accuracy 0.875000 - Val Accuracy 0.843750\n",
      "Epoch  8, Batch 341/429 - Loss   314.4614 Train Accuracy 0.843750 - Val Accuracy 0.851562\n",
      "Epoch  8, Batch 351/429 - Loss   287.5662 Train Accuracy 0.890625 - Val Accuracy 0.859375\n",
      "Epoch  8, Batch 361/429 - Loss   215.4408 Train Accuracy 0.875000 - Val Accuracy 0.859375\n",
      "Epoch  8, Batch 371/429 - Loss   291.8847 Train Accuracy 0.851562 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 381/429 - Loss   249.4853 Train Accuracy 0.867188 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 391/429 - Loss   328.3790 Train Accuracy 0.843750 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 401/429 - Loss   264.1440 Train Accuracy 0.882812 - Val Accuracy 0.855469\n",
      "Epoch  8, Batch 411/429 - Loss   433.0428 Train Accuracy 0.820312 - Val Accuracy 0.863281\n",
      "Epoch  8, Batch 421/429 - Loss   233.0048 Train Accuracy 0.882812 - Val Accuracy 0.859375\n",
      "Epoch  9, Batch   1/429 - Loss   206.3320 Train Accuracy 0.875000 - Val Accuracy 0.859375\n",
      "Epoch  9, Batch  11/429 - Loss   383.3263 Train Accuracy 0.820312 - Val Accuracy 0.855469\n",
      "Epoch  9, Batch  21/429 - Loss   460.4169 Train Accuracy 0.835938 - Val Accuracy 0.859375\n",
      "Epoch  9, Batch  31/429 - Loss   325.7253 Train Accuracy 0.835938 - Val Accuracy 0.847656\n",
      "Epoch  9, Batch  41/429 - Loss   171.4271 Train Accuracy 0.898438 - Val Accuracy 0.851562\n",
      "Epoch  9, Batch  51/429 - Loss   293.4542 Train Accuracy 0.851562 - Val Accuracy 0.851562\n",
      "Epoch  9, Batch  61/429 - Loss   270.6735 Train Accuracy 0.867188 - Val Accuracy 0.847656\n",
      "Epoch  9, Batch  71/429 - Loss   347.2976 Train Accuracy 0.828125 - Val Accuracy 0.851562\n",
      "Epoch  9, Batch  81/429 - Loss   355.3970 Train Accuracy 0.859375 - Val Accuracy 0.855469\n",
      "Epoch  9, Batch  91/429 - Loss   204.1796 Train Accuracy 0.898438 - Val Accuracy 0.851562\n",
      "Epoch  9, Batch 101/429 - Loss   332.9097 Train Accuracy 0.859375 - Val Accuracy 0.851562\n",
      "Epoch  9, Batch 111/429 - Loss   202.6316 Train Accuracy 0.867188 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 121/429 - Loss   326.3183 Train Accuracy 0.851562 - Val Accuracy 0.867188\n",
      "Epoch  9, Batch 131/429 - Loss   384.1234 Train Accuracy 0.859375 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 141/429 - Loss   208.2522 Train Accuracy 0.851562 - Val Accuracy 0.859375\n",
      "Epoch  9, Batch 151/429 - Loss   327.8436 Train Accuracy 0.828125 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 161/429 - Loss   289.3307 Train Accuracy 0.875000 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 171/429 - Loss   258.0641 Train Accuracy 0.898438 - Val Accuracy 0.855469\n",
      "Epoch  9, Batch 181/429 - Loss   341.9421 Train Accuracy 0.835938 - Val Accuracy 0.859375\n",
      "Epoch  9, Batch 191/429 - Loss   342.7842 Train Accuracy 0.843750 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 201/429 - Loss   218.2656 Train Accuracy 0.882812 - Val Accuracy 0.855469\n",
      "Epoch  9, Batch 211/429 - Loss   191.1029 Train Accuracy 0.875000 - Val Accuracy 0.855469\n",
      "Epoch  9, Batch 221/429 - Loss   401.9917 Train Accuracy 0.812500 - Val Accuracy 0.855469\n",
      "Epoch  9, Batch 231/429 - Loss   147.9000 Train Accuracy 0.898438 - Val Accuracy 0.851562\n",
      "Epoch  9, Batch 241/429 - Loss   427.2389 Train Accuracy 0.828125 - Val Accuracy 0.855469\n",
      "Epoch  9, Batch 251/429 - Loss   407.7073 Train Accuracy 0.835938 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 261/429 - Loss   234.5803 Train Accuracy 0.867188 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 271/429 - Loss   303.7980 Train Accuracy 0.898438 - Val Accuracy 0.867188\n",
      "Epoch  9, Batch 281/429 - Loss   262.2649 Train Accuracy 0.875000 - Val Accuracy 0.867188\n",
      "Epoch  9, Batch 291/429 - Loss   319.1089 Train Accuracy 0.812500 - Val Accuracy 0.867188\n",
      "Epoch  9, Batch 301/429 - Loss   404.7486 Train Accuracy 0.859375 - Val Accuracy 0.867188\n",
      "Epoch  9, Batch 311/429 - Loss   211.1936 Train Accuracy 0.867188 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 321/429 - Loss   263.7126 Train Accuracy 0.835938 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 331/429 - Loss   412.8537 Train Accuracy 0.812500 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 341/429 - Loss   236.2283 Train Accuracy 0.882812 - Val Accuracy 0.867188\n",
      "Epoch  9, Batch 351/429 - Loss   521.5480 Train Accuracy 0.750000 - Val Accuracy 0.871094\n",
      "Epoch  9, Batch 361/429 - Loss   236.9279 Train Accuracy 0.835938 - Val Accuracy 0.867188\n",
      "Epoch  9, Batch 371/429 - Loss   244.4512 Train Accuracy 0.875000 - Val Accuracy 0.871094\n",
      "Epoch  9, Batch 381/429 - Loss   340.7278 Train Accuracy 0.851562 - Val Accuracy 0.867188\n",
      "Epoch  9, Batch 391/429 - Loss   391.6863 Train Accuracy 0.820312 - Val Accuracy 0.859375\n",
      "Epoch  9, Batch 401/429 - Loss   188.8452 Train Accuracy 0.867188 - Val Accuracy 0.863281\n",
      "Epoch  9, Batch 411/429 - Loss   176.3403 Train Accuracy 0.914062 - Val Accuracy 0.867188\n",
      "Epoch  9, Batch 421/429 - Loss   241.3823 Train Accuracy 0.843750 - Val Accuracy 0.867188\n",
      "Epoch 10, Batch   1/429 - Loss   287.0623 Train Accuracy 0.882812 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch  11/429 - Loss   239.3696 Train Accuracy 0.843750 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch  21/429 - Loss   221.5009 Train Accuracy 0.867188 - Val Accuracy 0.878906\n",
      "Epoch 10, Batch  31/429 - Loss   313.3422 Train Accuracy 0.843750 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch  41/429 - Loss   245.5458 Train Accuracy 0.867188 - Val Accuracy 0.875000\n",
      "Epoch 10, Batch  51/429 - Loss   322.9760 Train Accuracy 0.812500 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch  61/429 - Loss   228.9787 Train Accuracy 0.859375 - Val Accuracy 0.867188\n",
      "Epoch 10, Batch  71/429 - Loss   193.5549 Train Accuracy 0.898438 - Val Accuracy 0.867188\n",
      "Epoch 10, Batch  81/429 - Loss   269.1161 Train Accuracy 0.835938 - Val Accuracy 0.867188\n",
      "Epoch 10, Batch  91/429 - Loss   378.4935 Train Accuracy 0.796875 - Val Accuracy 0.867188\n",
      "Epoch 10, Batch 101/429 - Loss   281.4071 Train Accuracy 0.875000 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 111/429 - Loss   170.0850 Train Accuracy 0.859375 - Val Accuracy 0.867188\n",
      "Epoch 10, Batch 121/429 - Loss   239.6694 Train Accuracy 0.812500 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 131/429 - Loss   316.0576 Train Accuracy 0.828125 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 141/429 - Loss   410.6428 Train Accuracy 0.781250 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 151/429 - Loss   243.6557 Train Accuracy 0.859375 - Val Accuracy 0.859375\n",
      "Epoch 10, Batch 161/429 - Loss   273.4523 Train Accuracy 0.828125 - Val Accuracy 0.859375\n",
      "Epoch 10, Batch 171/429 - Loss   192.2246 Train Accuracy 0.867188 - Val Accuracy 0.859375\n",
      "Epoch 10, Batch 181/429 - Loss   265.6197 Train Accuracy 0.828125 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 191/429 - Loss   158.0801 Train Accuracy 0.875000 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 201/429 - Loss   144.6083 Train Accuracy 0.898438 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 211/429 - Loss   261.1019 Train Accuracy 0.890625 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 221/429 - Loss   169.2378 Train Accuracy 0.898438 - Val Accuracy 0.859375\n",
      "Epoch 10, Batch 231/429 - Loss   171.3137 Train Accuracy 0.882812 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 241/429 - Loss   396.0399 Train Accuracy 0.875000 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 251/429 - Loss   163.1441 Train Accuracy 0.906250 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 261/429 - Loss   285.1594 Train Accuracy 0.867188 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 271/429 - Loss   359.5056 Train Accuracy 0.820312 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 281/429 - Loss   324.0798 Train Accuracy 0.867188 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 291/429 - Loss   118.3709 Train Accuracy 0.914062 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 301/429 - Loss   207.8637 Train Accuracy 0.875000 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 311/429 - Loss   234.4724 Train Accuracy 0.851562 - Val Accuracy 0.867188\n",
      "Epoch 10, Batch 321/429 - Loss   300.0953 Train Accuracy 0.835938 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 331/429 - Loss   185.4036 Train Accuracy 0.867188 - Val Accuracy 0.867188\n",
      "Epoch 10, Batch 341/429 - Loss   413.3800 Train Accuracy 0.859375 - Val Accuracy 0.867188\n",
      "Epoch 10, Batch 351/429 - Loss   400.8740 Train Accuracy 0.820312 - Val Accuracy 0.863281\n",
      "Epoch 10, Batch 361/429 - Loss   337.9136 Train Accuracy 0.789062 - Val Accuracy 0.859375\n",
      "Epoch 10, Batch 371/429 - Loss   206.0716 Train Accuracy 0.882812 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 381/429 - Loss   221.8890 Train Accuracy 0.890625 - Val Accuracy 0.875000\n",
      "Epoch 10, Batch 391/429 - Loss   293.5480 Train Accuracy 0.851562 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 401/429 - Loss   228.6922 Train Accuracy 0.906250 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 411/429 - Loss   218.5504 Train Accuracy 0.843750 - Val Accuracy 0.871094\n",
      "Epoch 10, Batch 421/429 - Loss   315.2294 Train Accuracy 0.828125 - Val Accuracy 0.875000\n",
      "Testing Accuracy: 0.828125\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    num_batches = int(mnist.train.num_examples / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(int(mnist.train.num_examples / batch_size)):\n",
    "            images, labels = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            sess.run(optimizer, \n",
    "                     feed_dict = {\n",
    "                         x : images,\n",
    "                         y : labels,\n",
    "                         keep_prob : dropout\n",
    "                     })\n",
    "            if batch % 10 == 0:\n",
    "                train_loss, train_acc = sess.run([cost, accuracy], \n",
    "                                       feed_dict={\n",
    "                                             x : images,\n",
    "                                             y : labels,\n",
    "                                             keep_prob : 1.0                                           \n",
    "                                       })\n",
    "                valid_acc = sess.run(accuracy,\n",
    "                                feed_dict={\n",
    "                                    x: mnist.validation.images[:test_valid_size],\n",
    "                                    y: mnist.validation.labels[:test_valid_size],\n",
    "                                    keep_prob: 1.0\n",
    "                                })\n",
    "                print('Epoch {:>2}, Batch {:>3}/{:>2} - Loss {:>10.4f} Train Accuracy {:.6f} - Val Accuracy {:.6f}'\\\n",
    "                     .format(epoch + 1, batch + 1, num_batches, train_loss, train_acc, valid_acc)\n",
    "                     )\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.0\n",
    "    })\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batches 429\n"
     ]
    }
   ],
   "source": [
    "print('num batches', int(mnist.train.num_examples / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}