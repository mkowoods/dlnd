{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Q-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-17 22:57:34,140] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "rewards = []\n",
    "for _ in range(100):\n",
    "    env.render()\n",
    "    state, reward, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    rewards.append(reward)\n",
    "    if done:\n",
    "        rewards = []\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class QNetwork:\n",
    "    def __init__(self, learning_rate=0.01, state_size=4, \n",
    "                 action_size=2, hidden_size=10, \n",
    "                 name='QNetwork'):\n",
    "        # state inputs to the Q-network\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "            \n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc2, action_size, \n",
    "                                                            activation_fn=None)\n",
    "            \n",
    "            ### Train with loss (targetQ - Q)^2\n",
    "            # output has length 2, for two actions. This next line chooses\n",
    "            # one value from output (per row) according to the one-hot encoded actions.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 225                # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.001            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    # env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Steps: 21 Total reward: 22.0 Training loss: 1.0234 Explore P: 0.9978\n",
      "Episode: 2 Steps: 8 Total reward: 9.0 Training loss: 1.0191 Explore P: 0.9969\n",
      "Episode: 3 Steps: 16 Total reward: 17.0 Training loss: 1.0310 Explore P: 0.9952\n",
      "Episode: 4 Steps: 31 Total reward: 32.0 Training loss: 1.0184 Explore P: 0.9920\n",
      "Episode: 5 Steps: 9 Total reward: 10.0 Training loss: 0.9999 Explore P: 0.9910\n",
      "Episode: 6 Steps: 24 Total reward: 25.0 Training loss: 1.0801 Explore P: 0.9886\n",
      "Episode: 7 Steps: 14 Total reward: 15.0 Training loss: 1.0289 Explore P: 0.9871\n",
      "Episode: 8 Steps: 26 Total reward: 27.0 Training loss: 1.0377 Explore P: 0.9844\n",
      "Episode: 9 Steps: 39 Total reward: 40.0 Training loss: 0.9947 Explore P: 0.9805\n",
      "Episode: 10 Steps: 28 Total reward: 29.0 Training loss: 1.0731 Explore P: 0.9777\n",
      "Episode: 11 Steps: 15 Total reward: 16.0 Training loss: 1.0890 Explore P: 0.9761\n",
      "Episode: 12 Steps: 13 Total reward: 14.0 Training loss: 1.0625 Explore P: 0.9748\n",
      "Episode: 13 Steps: 11 Total reward: 12.0 Training loss: 1.0969 Explore P: 0.9736\n",
      "Episode: 14 Steps: 14 Total reward: 15.0 Training loss: 1.2442 Explore P: 0.9721\n",
      "Episode: 15 Steps: 13 Total reward: 14.0 Training loss: 1.0572 Explore P: 0.9708\n",
      "Episode: 16 Steps: 14 Total reward: 15.0 Training loss: 1.1615 Explore P: 0.9693\n",
      "Episode: 17 Steps: 37 Total reward: 38.0 Training loss: 1.0678 Explore P: 0.9656\n",
      "Episode: 18 Steps: 13 Total reward: 14.0 Training loss: 1.5743 Explore P: 0.9643\n",
      "Episode: 19 Steps: 31 Total reward: 32.0 Training loss: 1.7200 Explore P: 0.9612\n",
      "Episode: 20 Steps: 8 Total reward: 9.0 Training loss: 1.3923 Explore P: 0.9603\n",
      "Episode: 21 Steps: 11 Total reward: 12.0 Training loss: 1.2825 Explore P: 0.9592\n",
      "Episode: 22 Steps: 13 Total reward: 14.0 Training loss: 1.5563 Explore P: 0.9579\n",
      "Episode: 23 Steps: 18 Total reward: 19.0 Training loss: 1.0301 Explore P: 0.9560\n",
      "Episode: 24 Steps: 30 Total reward: 31.0 Training loss: 1.4572 Explore P: 0.9531\n",
      "Episode: 25 Steps: 12 Total reward: 13.0 Training loss: 1.2439 Explore P: 0.9518\n",
      "Episode: 26 Steps: 13 Total reward: 14.0 Training loss: 1.1140 Explore P: 0.9505\n",
      "Episode: 27 Steps: 7 Total reward: 8.0 Training loss: 1.4792 Explore P: 0.9498\n",
      "Episode: 28 Steps: 19 Total reward: 20.0 Training loss: 0.9152 Explore P: 0.9479\n",
      "Episode: 29 Steps: 14 Total reward: 15.0 Training loss: 1.2127 Explore P: 0.9464\n",
      "Episode: 30 Steps: 41 Total reward: 42.0 Training loss: 1.3627 Explore P: 0.9425\n",
      "Episode: 31 Steps: 16 Total reward: 17.0 Training loss: 1.4034 Explore P: 0.9409\n",
      "Episode: 32 Steps: 24 Total reward: 25.0 Training loss: 0.9311 Explore P: 0.9385\n",
      "Episode: 33 Steps: 48 Total reward: 49.0 Training loss: 1.5995 Explore P: 0.9340\n",
      "Episode: 34 Steps: 40 Total reward: 41.0 Training loss: 1.4160 Explore P: 0.9301\n",
      "Episode: 35 Steps: 27 Total reward: 28.0 Training loss: 1.6348 Explore P: 0.9275\n",
      "Episode: 36 Steps: 16 Total reward: 17.0 Training loss: 1.0762 Explore P: 0.9260\n",
      "Episode: 37 Steps: 13 Total reward: 14.0 Training loss: 4.6301 Explore P: 0.9247\n",
      "Episode: 38 Steps: 27 Total reward: 28.0 Training loss: 1.8156 Explore P: 0.9221\n",
      "Episode: 39 Steps: 8 Total reward: 9.0 Training loss: 1.0476 Explore P: 0.9213\n",
      "Episode: 40 Steps: 15 Total reward: 16.0 Training loss: 5.2744 Explore P: 0.9198\n",
      "Episode: 41 Steps: 23 Total reward: 24.0 Training loss: 1.3195 Explore P: 0.9176\n",
      "Episode: 42 Steps: 12 Total reward: 13.0 Training loss: 1.1232 Explore P: 0.9164\n",
      "Episode: 43 Steps: 11 Total reward: 12.0 Training loss: 1.5459 Explore P: 0.9153\n",
      "Episode: 44 Steps: 36 Total reward: 37.0 Training loss: 2.5038 Explore P: 0.9119\n",
      "Episode: 45 Steps: 35 Total reward: 36.0 Training loss: 2.7793 Explore P: 0.9086\n",
      "Episode: 46 Steps: 23 Total reward: 24.0 Training loss: 1.7153 Explore P: 0.9065\n",
      "Episode: 47 Steps: 22 Total reward: 23.0 Training loss: 2.4051 Explore P: 0.9044\n",
      "Episode: 48 Steps: 32 Total reward: 33.0 Training loss: 9.3159 Explore P: 0.9014\n",
      "Episode: 49 Steps: 9 Total reward: 10.0 Training loss: 2.9848 Explore P: 0.9005\n",
      "Episode: 50 Steps: 18 Total reward: 19.0 Training loss: 1.7023 Explore P: 0.8988\n",
      "Episode: 51 Steps: 21 Total reward: 22.0 Training loss: 22.0566 Explore P: 0.8968\n",
      "Episode: 52 Steps: 22 Total reward: 23.0 Training loss: 1.3427 Explore P: 0.8948\n",
      "Episode: 53 Steps: 36 Total reward: 37.0 Training loss: 1.1121 Explore P: 0.8915\n",
      "Episode: 54 Steps: 16 Total reward: 17.0 Training loss: 176.0048 Explore P: 0.8900\n",
      "Episode: 55 Steps: 9 Total reward: 10.0 Training loss: 2.1493 Explore P: 0.8891\n",
      "Episode: 56 Steps: 14 Total reward: 15.0 Training loss: 46.5819 Explore P: 0.8877\n",
      "Episode: 57 Steps: 26 Total reward: 27.0 Training loss: 1.2844 Explore P: 0.8854\n",
      "Episode: 58 Steps: 33 Total reward: 34.0 Training loss: 0.9649 Explore P: 0.8823\n",
      "Episode: 59 Steps: 9 Total reward: 10.0 Training loss: 73.2659 Explore P: 0.8815\n",
      "Episode: 60 Steps: 15 Total reward: 16.0 Training loss: 1.5096 Explore P: 0.8801\n",
      "Episode: 61 Steps: 23 Total reward: 24.0 Training loss: 0.9783 Explore P: 0.8780\n",
      "Episode: 62 Steps: 51 Total reward: 52.0 Training loss: 2.1389 Explore P: 0.8734\n",
      "Episode: 63 Steps: 30 Total reward: 31.0 Training loss: 1.2742 Explore P: 0.8707\n",
      "Episode: 64 Steps: 13 Total reward: 14.0 Training loss: 1.2558 Explore P: 0.8695\n",
      "Episode: 65 Steps: 11 Total reward: 12.0 Training loss: 24.1117 Explore P: 0.8684\n",
      "Episode: 66 Steps: 82 Total reward: 83.0 Training loss: 1.0817 Explore P: 0.8613\n",
      "Episode: 67 Steps: 16 Total reward: 17.0 Training loss: 2.3010 Explore P: 0.8598\n",
      "Episode: 68 Steps: 13 Total reward: 14.0 Training loss: 3.3955 Explore P: 0.8586\n",
      "Episode: 69 Steps: 25 Total reward: 26.0 Training loss: 1.3631 Explore P: 0.8564\n",
      "Episode: 70 Steps: 32 Total reward: 33.0 Training loss: 1.0019 Explore P: 0.8536\n",
      "Episode: 71 Steps: 25 Total reward: 26.0 Training loss: 2.5635 Explore P: 0.8514\n",
      "Episode: 72 Steps: 57 Total reward: 58.0 Training loss: 28.6183 Explore P: 0.8464\n",
      "Episode: 73 Steps: 35 Total reward: 36.0 Training loss: 1.3915 Explore P: 0.8434\n",
      "Episode: 74 Steps: 24 Total reward: 25.0 Training loss: 2.0152 Explore P: 0.8413\n",
      "Episode: 75 Steps: 30 Total reward: 31.0 Training loss: 1.1469 Explore P: 0.8387\n",
      "Episode: 76 Steps: 23 Total reward: 24.0 Training loss: 1.4405 Explore P: 0.8367\n",
      "Episode: 77 Steps: 18 Total reward: 19.0 Training loss: 0.8007 Explore P: 0.8351\n",
      "Episode: 78 Steps: 53 Total reward: 54.0 Training loss: 1.0253 Explore P: 0.8306\n",
      "Episode: 79 Steps: 25 Total reward: 26.0 Training loss: 1.0971 Explore P: 0.8285\n",
      "Episode: 80 Steps: 44 Total reward: 45.0 Training loss: 1.0573 Explore P: 0.8247\n",
      "Episode: 81 Steps: 12 Total reward: 13.0 Training loss: 0.7369 Explore P: 0.8237\n",
      "Episode: 82 Steps: 41 Total reward: 42.0 Training loss: 0.7173 Explore P: 0.8202\n",
      "Episode: 83 Steps: 71 Total reward: 72.0 Training loss: 1.9005 Explore P: 0.8143\n",
      "Episode: 84 Steps: 48 Total reward: 49.0 Training loss: 2.1740 Explore P: 0.8104\n",
      "Episode: 85 Steps: 25 Total reward: 26.0 Training loss: 1.0076 Explore P: 0.8083\n",
      "Episode: 86 Steps: 61 Total reward: 62.0 Training loss: 29.7626 Explore P: 0.8033\n",
      "Episode: 87 Steps: 11 Total reward: 12.0 Training loss: 1.3859 Explore P: 0.8023\n",
      "Episode: 88 Steps: 29 Total reward: 30.0 Training loss: 1.8562 Explore P: 0.7999\n",
      "Episode: 89 Steps: 24 Total reward: 25.0 Training loss: 1.3363 Explore P: 0.7979\n",
      "Episode: 90 Steps: 15 Total reward: 16.0 Training loss: 153.7859 Explore P: 0.7966\n",
      "Episode: 91 Steps: 20 Total reward: 21.0 Training loss: 1.8613 Explore P: 0.7950\n",
      "Episode: 92 Steps: 10 Total reward: 11.0 Training loss: 1.8066 Explore P: 0.7941\n",
      "Episode: 93 Steps: 25 Total reward: 26.0 Training loss: 1.5670 Explore P: 0.7920\n",
      "Episode: 94 Steps: 18 Total reward: 19.0 Training loss: 189.8849 Explore P: 0.7905\n",
      "Episode: 95 Steps: 22 Total reward: 23.0 Training loss: 47.7632 Explore P: 0.7887\n",
      "Episode: 96 Steps: 26 Total reward: 27.0 Training loss: 2.4718 Explore P: 0.7866\n",
      "Episode: 97 Steps: 34 Total reward: 35.0 Training loss: 45.8910 Explore P: 0.7839\n",
      "Episode: 98 Steps: 17 Total reward: 18.0 Training loss: 1.2834 Explore P: 0.7825\n",
      "Episode: 99 Steps: 23 Total reward: 24.0 Training loss: 1.0427 Explore P: 0.7806\n",
      "Episode: 100 Steps: 15 Total reward: 16.0 Training loss: 1.2400 Explore P: 0.7793\n",
      "Episode: 101 Steps: 16 Total reward: 17.0 Training loss: 0.8542 Explore P: 0.7780\n",
      "Episode: 102 Steps: 37 Total reward: 38.0 Training loss: 0.6165 Explore P: 0.7751\n",
      "Episode: 103 Steps: 28 Total reward: 29.0 Training loss: 61.7345 Explore P: 0.7728\n",
      "Episode: 104 Steps: 21 Total reward: 22.0 Training loss: 41.5211 Explore P: 0.7711\n",
      "Episode: 105 Steps: 31 Total reward: 32.0 Training loss: 0.6744 Explore P: 0.7687\n",
      "Episode: 106 Steps: 29 Total reward: 30.0 Training loss: 1.1536 Explore P: 0.7664\n",
      "Episode: 107 Steps: 26 Total reward: 27.0 Training loss: 0.6272 Explore P: 0.7643\n",
      "Episode: 108 Steps: 14 Total reward: 15.0 Training loss: 0.7912 Explore P: 0.7632\n",
      "Episode: 109 Steps: 17 Total reward: 18.0 Training loss: 1.5417 Explore P: 0.7618\n",
      "Episode: 110 Steps: 65 Total reward: 66.0 Training loss: 76.2821 Explore P: 0.7568\n",
      "Episode: 111 Steps: 33 Total reward: 34.0 Training loss: 1.0980 Explore P: 0.7542\n",
      "Episode: 112 Steps: 9 Total reward: 10.0 Training loss: 1.3976 Explore P: 0.7535\n",
      "Episode: 113 Steps: 88 Total reward: 89.0 Training loss: 0.7361 Explore P: 0.7468\n",
      "Episode: 114 Steps: 16 Total reward: 17.0 Training loss: 0.8069 Explore P: 0.7455\n",
      "Episode: 115 Steps: 15 Total reward: 16.0 Training loss: 114.6586 Explore P: 0.7443\n",
      "Episode: 116 Steps: 23 Total reward: 24.0 Training loss: 81.0241 Explore P: 0.7426\n",
      "Episode: 117 Steps: 45 Total reward: 46.0 Training loss: 0.9535 Explore P: 0.7392\n",
      "Episode: 118 Steps: 29 Total reward: 30.0 Training loss: 1.3414 Explore P: 0.7369\n",
      "Episode: 119 Steps: 9 Total reward: 10.0 Training loss: 67.7504 Explore P: 0.7362\n",
      "Episode: 120 Steps: 12 Total reward: 13.0 Training loss: 262.3468 Explore P: 0.7353\n",
      "Episode: 121 Steps: 44 Total reward: 45.0 Training loss: 1.5794 Explore P: 0.7320\n",
      "Episode: 122 Steps: 20 Total reward: 21.0 Training loss: 35.4495 Explore P: 0.7304\n",
      "Episode: 123 Steps: 20 Total reward: 21.0 Training loss: 0.7089 Explore P: 0.7289\n",
      "Episode: 124 Steps: 13 Total reward: 14.0 Training loss: 101.5695 Explore P: 0.7279\n",
      "Episode: 125 Steps: 19 Total reward: 20.0 Training loss: 0.6516 Explore P: 0.7264\n",
      "Episode: 126 Steps: 33 Total reward: 34.0 Training loss: 0.6524 Explore P: 0.7240\n",
      "Episode: 127 Steps: 85 Total reward: 86.0 Training loss: 0.8017 Explore P: 0.7178\n",
      "Episode: 128 Steps: 24 Total reward: 25.0 Training loss: 0.8220 Explore P: 0.7160\n",
      "Episode: 129 Steps: 22 Total reward: 23.0 Training loss: 1.4682 Explore P: 0.7143\n",
      "Episode: 130 Steps: 56 Total reward: 57.0 Training loss: 37.4587 Explore P: 0.7103\n",
      "Episode: 131 Steps: 42 Total reward: 43.0 Training loss: 392.9614 Explore P: 0.7072\n",
      "Episode: 132 Steps: 18 Total reward: 19.0 Training loss: 1.5121 Explore P: 0.7059\n",
      "Episode: 133 Steps: 11 Total reward: 12.0 Training loss: 52.9247 Explore P: 0.7051\n",
      "Episode: 134 Steps: 15 Total reward: 16.0 Training loss: 152.2991 Explore P: 0.7039\n",
      "Episode: 135 Steps: 26 Total reward: 27.0 Training loss: 0.4108 Explore P: 0.7020\n",
      "Episode: 136 Steps: 30 Total reward: 31.0 Training loss: 0.9209 Explore P: 0.6999\n",
      "Episode: 137 Steps: 80 Total reward: 81.0 Training loss: 0.5993 Explore P: 0.6942\n",
      "Episode: 138 Steps: 13 Total reward: 14.0 Training loss: 0.6505 Explore P: 0.6933\n",
      "Episode: 139 Steps: 79 Total reward: 80.0 Training loss: 1.1850 Explore P: 0.6877\n",
      "Episode: 140 Steps: 18 Total reward: 19.0 Training loss: 1.2563 Explore P: 0.6864\n",
      "Episode: 141 Steps: 10 Total reward: 11.0 Training loss: 206.8530 Explore P: 0.6857\n",
      "Episode: 142 Steps: 36 Total reward: 37.0 Training loss: 0.6821 Explore P: 0.6832\n",
      "Episode: 143 Steps: 60 Total reward: 61.0 Training loss: 1.3271 Explore P: 0.6790\n",
      "Episode: 144 Steps: 33 Total reward: 34.0 Training loss: 1.3328 Explore P: 0.6767\n",
      "Episode: 145 Steps: 61 Total reward: 62.0 Training loss: 0.4625 Explore P: 0.6725\n",
      "Episode: 146 Steps: 21 Total reward: 22.0 Training loss: 84.5214 Explore P: 0.6711\n",
      "Episode: 147 Steps: 33 Total reward: 34.0 Training loss: 0.6810 Explore P: 0.6688\n",
      "Episode: 148 Steps: 21 Total reward: 22.0 Training loss: 56.4535 Explore P: 0.6673\n",
      "Episode: 149 Steps: 20 Total reward: 21.0 Training loss: 34.4541 Explore P: 0.6659\n",
      "Episode: 150 Steps: 30 Total reward: 31.0 Training loss: 50.8042 Explore P: 0.6639\n",
      "Episode: 151 Steps: 60 Total reward: 61.0 Training loss: 1.2036 Explore P: 0.6598\n",
      "Episode: 152 Steps: 11 Total reward: 12.0 Training loss: 82.2906 Explore P: 0.6590\n",
      "Episode: 153 Steps: 15 Total reward: 16.0 Training loss: 0.8998 Explore P: 0.6580\n",
      "Episode: 154 Steps: 34 Total reward: 35.0 Training loss: 0.8730 Explore P: 0.6557\n",
      "Episode: 155 Steps: 17 Total reward: 18.0 Training loss: 1.3573 Explore P: 0.6545\n",
      "Episode: 156 Steps: 11 Total reward: 12.0 Training loss: 1.0629 Explore P: 0.6537\n",
      "Episode: 157 Steps: 13 Total reward: 14.0 Training loss: 1.0237 Explore P: 0.6528\n",
      "Episode: 158 Steps: 22 Total reward: 23.0 Training loss: 0.7941 Explore P: 0.6513\n",
      "Episode: 159 Steps: 13 Total reward: 14.0 Training loss: 42.3003 Explore P: 0.6504\n",
      "Episode: 160 Steps: 16 Total reward: 17.0 Training loss: 87.3430 Explore P: 0.6493\n",
      "Episode: 161 Steps: 12 Total reward: 13.0 Training loss: 1.1181 Explore P: 0.6485\n",
      "Episode: 162 Steps: 13 Total reward: 14.0 Training loss: 368.2914 Explore P: 0.6476\n",
      "Episode: 163 Steps: 20 Total reward: 21.0 Training loss: 0.4812 Explore P: 0.6462\n",
      "Episode: 164 Steps: 93 Total reward: 94.0 Training loss: 0.6315 Explore P: 0.6402\n",
      "Episode: 165 Steps: 20 Total reward: 21.0 Training loss: 59.2058 Explore P: 0.6388\n",
      "Episode: 166 Steps: 36 Total reward: 37.0 Training loss: 0.5880 Explore P: 0.6365\n",
      "Episode: 167 Steps: 49 Total reward: 50.0 Training loss: 0.6785 Explore P: 0.6333\n",
      "Episode: 168 Steps: 34 Total reward: 35.0 Training loss: 0.6033 Explore P: 0.6311\n",
      "Episode: 169 Steps: 41 Total reward: 42.0 Training loss: 86.9946 Explore P: 0.6284\n",
      "Episode: 170 Steps: 17 Total reward: 18.0 Training loss: 0.6069 Explore P: 0.6273\n",
      "Episode: 171 Steps: 28 Total reward: 29.0 Training loss: 0.5279 Explore P: 0.6255\n",
      "Episode: 172 Steps: 22 Total reward: 23.0 Training loss: 48.8148 Explore P: 0.6241\n",
      "Episode: 173 Steps: 76 Total reward: 77.0 Training loss: 0.6461 Explore P: 0.6193\n",
      "Episode: 174 Steps: 10 Total reward: 11.0 Training loss: 0.6082 Explore P: 0.6186\n",
      "Episode: 175 Steps: 46 Total reward: 47.0 Training loss: 0.9495 Explore P: 0.6157\n",
      "Episode: 176 Steps: 17 Total reward: 18.0 Training loss: 111.2060 Explore P: 0.6146\n",
      "Episode: 177 Steps: 8 Total reward: 9.0 Training loss: 37.3050 Explore P: 0.6141\n",
      "Episode: 178 Steps: 13 Total reward: 14.0 Training loss: 0.7807 Explore P: 0.6132\n",
      "Episode: 179 Steps: 8 Total reward: 9.0 Training loss: 0.7370 Explore P: 0.6126\n",
      "Episode: 180 Steps: 10 Total reward: 11.0 Training loss: 0.7808 Explore P: 0.6120\n",
      "Episode: 181 Steps: 17 Total reward: 18.0 Training loss: 49.6287 Explore P: 0.6109\n",
      "Episode: 182 Steps: 50 Total reward: 51.0 Training loss: 0.8699 Explore P: 0.6078\n",
      "Episode: 183 Steps: 18 Total reward: 19.0 Training loss: 137.4841 Explore P: 0.6066\n",
      "Episode: 184 Steps: 20 Total reward: 21.0 Training loss: 0.5908 Explore P: 0.6054\n",
      "Episode: 185 Steps: 33 Total reward: 34.0 Training loss: 0.5510 Explore P: 0.6033\n",
      "Episode: 186 Steps: 45 Total reward: 46.0 Training loss: 0.5113 Explore P: 0.6005\n",
      "Episode: 187 Steps: 42 Total reward: 43.0 Training loss: 71.4664 Explore P: 0.5980\n",
      "Episode: 188 Steps: 33 Total reward: 34.0 Training loss: 82.6000 Explore P: 0.5959\n",
      "Episode: 189 Steps: 9 Total reward: 10.0 Training loss: 83.6390 Explore P: 0.5953\n",
      "Episode: 190 Steps: 27 Total reward: 28.0 Training loss: 0.4246 Explore P: 0.5937\n",
      "Episode: 191 Steps: 33 Total reward: 34.0 Training loss: 0.5448 Explore P: 0.5917\n",
      "Episode: 192 Steps: 17 Total reward: 18.0 Training loss: 0.7649 Explore P: 0.5906\n",
      "Episode: 193 Steps: 28 Total reward: 29.0 Training loss: 0.7146 Explore P: 0.5889\n",
      "Episode: 194 Steps: 77 Total reward: 78.0 Training loss: 0.6250 Explore P: 0.5843\n",
      "Episode: 195 Steps: 49 Total reward: 50.0 Training loss: 0.7093 Explore P: 0.5814\n",
      "Episode: 196 Steps: 21 Total reward: 22.0 Training loss: 0.4262 Explore P: 0.5801\n",
      "Episode: 197 Steps: 24 Total reward: 25.0 Training loss: 0.6339 Explore P: 0.5787\n",
      "Episode: 198 Steps: 74 Total reward: 75.0 Training loss: 0.5445 Explore P: 0.5744\n",
      "Episode: 199 Steps: 56 Total reward: 57.0 Training loss: 0.5723 Explore P: 0.5711\n",
      "Episode: 200 Steps: 7 Total reward: 8.0 Training loss: 0.7575 Explore P: 0.5707\n",
      "Episode: 201 Steps: 9 Total reward: 10.0 Training loss: 0.6357 Explore P: 0.5701\n",
      "Episode: 202 Steps: 13 Total reward: 14.0 Training loss: 0.6698 Explore P: 0.5693\n",
      "Episode: 203 Steps: 43 Total reward: 44.0 Training loss: 0.6650 Explore P: 0.5668\n",
      "Episode: 204 Steps: 25 Total reward: 26.0 Training loss: 36.9668 Explore P: 0.5653\n",
      "Episode: 205 Steps: 14 Total reward: 15.0 Training loss: 0.5318 Explore P: 0.5645\n",
      "Episode: 206 Steps: 19 Total reward: 20.0 Training loss: 71.4031 Explore P: 0.5634\n",
      "Episode: 207 Steps: 14 Total reward: 15.0 Training loss: 0.6508 Explore P: 0.5625\n",
      "Episode: 208 Steps: 11 Total reward: 12.0 Training loss: 0.5342 Explore P: 0.5619\n",
      "Episode: 209 Steps: 11 Total reward: 12.0 Training loss: 0.6686 Explore P: 0.5612\n",
      "Episode: 210 Steps: 13 Total reward: 14.0 Training loss: 0.4918 Explore P: 0.5604\n",
      "Episode: 211 Steps: 21 Total reward: 22.0 Training loss: 0.4632 Explore P: 0.5592\n",
      "Episode: 212 Steps: 23 Total reward: 24.0 Training loss: 0.6409 Explore P: 0.5578\n",
      "Episode: 213 Steps: 20 Total reward: 21.0 Training loss: 38.6965 Explore P: 0.5567\n",
      "Episode: 214 Steps: 50 Total reward: 51.0 Training loss: 0.6657 Explore P: 0.5538\n",
      "Episode: 215 Steps: 27 Total reward: 28.0 Training loss: 0.5767 Explore P: 0.5523\n",
      "Episode: 216 Steps: 57 Total reward: 58.0 Training loss: 86.9467 Explore P: 0.5491\n",
      "Episode: 217 Steps: 22 Total reward: 23.0 Training loss: 0.6311 Explore P: 0.5478\n",
      "Episode: 218 Steps: 16 Total reward: 17.0 Training loss: 0.6756 Explore P: 0.5469\n",
      "Episode: 219 Steps: 11 Total reward: 12.0 Training loss: 72.1565 Explore P: 0.5463\n",
      "Episode: 220 Steps: 10 Total reward: 11.0 Training loss: 0.5772 Explore P: 0.5457\n",
      "Episode: 221 Steps: 11 Total reward: 12.0 Training loss: 81.0194 Explore P: 0.5450\n",
      "Episode: 222 Steps: 31 Total reward: 32.0 Training loss: 49.8883 Explore P: 0.5433\n",
      "Episode: 223 Steps: 18 Total reward: 19.0 Training loss: 0.7971 Explore P: 0.5422\n",
      "Episode: 224 Steps: 29 Total reward: 30.0 Training loss: 308.3893 Explore P: 0.5406\n",
      "Episode: 225 Steps: 24 Total reward: 25.0 Training loss: 78.7380 Explore P: 0.5393\n",
      "Episode: 226 Steps: 99 Total reward: 100.0 Training loss: 0.4012 Explore P: 0.5339\n",
      "Episode: 227 Steps: 75 Total reward: 76.0 Training loss: 0.7495 Explore P: 0.5299\n",
      "Episode: 228 Steps: 11 Total reward: 12.0 Training loss: 0.5980 Explore P: 0.5292\n",
      "Episode: 229 Steps: 15 Total reward: 16.0 Training loss: 0.6637 Explore P: 0.5284\n",
      "Episode: 230 Steps: 18 Total reward: 19.0 Training loss: 0.8293 Explore P: 0.5274\n",
      "Episode: 231 Steps: 14 Total reward: 15.0 Training loss: 0.8355 Explore P: 0.5266\n",
      "Episode: 232 Steps: 15 Total reward: 16.0 Training loss: 0.8164 Explore P: 0.5258\n",
      "Episode: 233 Steps: 23 Total reward: 24.0 Training loss: 0.6642 Explore P: 0.5245\n",
      "Episode: 234 Steps: 16 Total reward: 17.0 Training loss: 0.5983 Explore P: 0.5236\n",
      "Episode: 235 Steps: 36 Total reward: 37.0 Training loss: 0.6310 Explore P: 0.5217\n",
      "Episode: 236 Steps: 37 Total reward: 38.0 Training loss: 0.8311 Explore P: 0.5197\n",
      "Episode: 237 Steps: 17 Total reward: 18.0 Training loss: 36.7583 Explore P: 0.5188\n",
      "Episode: 238 Steps: 16 Total reward: 17.0 Training loss: 0.8283 Explore P: 0.5179\n",
      "Episode: 239 Steps: 13 Total reward: 14.0 Training loss: 38.5743 Explore P: 0.5172\n",
      "Episode: 240 Steps: 35 Total reward: 36.0 Training loss: 46.8559 Explore P: 0.5153\n",
      "Episode: 241 Steps: 26 Total reward: 27.0 Training loss: 54.1798 Explore P: 0.5139\n",
      "Episode: 242 Steps: 67 Total reward: 68.0 Training loss: 31.5506 Explore P: 0.5105\n",
      "Episode: 243 Steps: 24 Total reward: 25.0 Training loss: 0.8104 Explore P: 0.5092\n",
      "Episode: 244 Steps: 19 Total reward: 20.0 Training loss: 36.3683 Explore P: 0.5082\n",
      "Episode: 245 Steps: 15 Total reward: 16.0 Training loss: 0.7594 Explore P: 0.5074\n",
      "Episode: 246 Steps: 32 Total reward: 33.0 Training loss: 0.4419 Explore P: 0.5057\n",
      "Episode: 247 Steps: 40 Total reward: 41.0 Training loss: 0.5610 Explore P: 0.5036\n",
      "Episode: 248 Steps: 31 Total reward: 32.0 Training loss: 0.5843 Explore P: 0.5020\n",
      "Episode: 249 Steps: 32 Total reward: 33.0 Training loss: 110.9496 Explore P: 0.5004\n",
      "Episode: 250 Steps: 76 Total reward: 77.0 Training loss: 73.4891 Explore P: 0.4965\n",
      "Episode: 251 Steps: 10 Total reward: 11.0 Training loss: 0.6893 Explore P: 0.4960\n",
      "Episode: 252 Steps: 54 Total reward: 55.0 Training loss: 0.5002 Explore P: 0.4933\n",
      "Episode: 253 Steps: 106 Total reward: 107.0 Training loss: 0.4577 Explore P: 0.4880\n",
      "Episode: 254 Steps: 50 Total reward: 51.0 Training loss: 78.9348 Explore P: 0.4856\n",
      "Episode: 255 Steps: 56 Total reward: 57.0 Training loss: 0.5871 Explore P: 0.4828\n",
      "Episode: 256 Steps: 31 Total reward: 32.0 Training loss: 0.6022 Explore P: 0.4813\n",
      "Episode: 257 Steps: 22 Total reward: 23.0 Training loss: 0.7870 Explore P: 0.4802\n",
      "Episode: 258 Steps: 68 Total reward: 69.0 Training loss: 28.2576 Explore P: 0.4769\n",
      "Episode: 259 Steps: 18 Total reward: 19.0 Training loss: 0.6059 Explore P: 0.4760\n",
      "Episode: 260 Steps: 26 Total reward: 27.0 Training loss: 0.6220 Explore P: 0.4747\n",
      "Episode: 261 Steps: 24 Total reward: 25.0 Training loss: 0.6669 Explore P: 0.4735\n",
      "Episode: 262 Steps: 63 Total reward: 64.0 Training loss: 0.6261 Explore P: 0.4705\n",
      "Episode: 263 Steps: 40 Total reward: 41.0 Training loss: 0.6850 Explore P: 0.4686\n",
      "Episode: 264 Steps: 31 Total reward: 32.0 Training loss: 28.2602 Explore P: 0.4671\n",
      "Episode: 265 Steps: 38 Total reward: 39.0 Training loss: 0.6607 Explore P: 0.4653\n",
      "Episode: 266 Steps: 40 Total reward: 41.0 Training loss: 0.6765 Explore P: 0.4634\n",
      "Episode: 267 Steps: 15 Total reward: 16.0 Training loss: 64.1204 Explore P: 0.4626\n",
      "Episode: 268 Steps: 48 Total reward: 49.0 Training loss: 0.6931 Explore P: 0.4604\n",
      "Episode: 269 Steps: 27 Total reward: 28.0 Training loss: 0.7839 Explore P: 0.4591\n",
      "Episode: 270 Steps: 18 Total reward: 19.0 Training loss: 42.3367 Explore P: 0.4582\n",
      "Episode: 271 Steps: 12 Total reward: 13.0 Training loss: 101.5414 Explore P: 0.4576\n",
      "Episode: 272 Steps: 11 Total reward: 12.0 Training loss: 35.0336 Explore P: 0.4571\n",
      "Episode: 273 Steps: 14 Total reward: 15.0 Training loss: 0.8013 Explore P: 0.4564\n",
      "Episode: 274 Steps: 16 Total reward: 17.0 Training loss: 0.8213 Explore P: 0.4556\n",
      "Episode: 275 Steps: 21 Total reward: 22.0 Training loss: 32.5061 Explore P: 0.4546\n",
      "Episode: 276 Steps: 51 Total reward: 52.0 Training loss: 0.4913 Explore P: 0.4523\n",
      "Episode: 277 Steps: 15 Total reward: 16.0 Training loss: 24.3369 Explore P: 0.4515\n",
      "Episode: 278 Steps: 30 Total reward: 31.0 Training loss: 0.6851 Explore P: 0.4501\n",
      "Episode: 279 Steps: 99 Total reward: 100.0 Training loss: 0.7566 Explore P: 0.4457\n",
      "Episode: 280 Steps: 24 Total reward: 25.0 Training loss: 1.2112 Explore P: 0.4446\n",
      "Episode: 281 Steps: 18 Total reward: 19.0 Training loss: 0.9626 Explore P: 0.4437\n",
      "Episode: 282 Steps: 38 Total reward: 39.0 Training loss: 100.1610 Explore P: 0.4420\n",
      "Episode: 283 Steps: 28 Total reward: 29.0 Training loss: 0.9685 Explore P: 0.4407\n",
      "Episode: 284 Steps: 32 Total reward: 33.0 Training loss: 90.6172 Explore P: 0.4393\n",
      "Episode: 285 Steps: 13 Total reward: 14.0 Training loss: 0.6550 Explore P: 0.4387\n",
      "Episode: 286 Steps: 30 Total reward: 31.0 Training loss: 0.4782 Explore P: 0.4373\n",
      "Episode: 287 Steps: 42 Total reward: 43.0 Training loss: 0.6260 Explore P: 0.4354\n",
      "Episode: 288 Steps: 33 Total reward: 34.0 Training loss: 0.8556 Explore P: 0.4340\n",
      "Episode: 289 Steps: 39 Total reward: 40.0 Training loss: 0.7297 Explore P: 0.4322\n",
      "Episode: 290 Steps: 75 Total reward: 76.0 Training loss: 0.8600 Explore P: 0.4290\n",
      "Episode: 291 Steps: 21 Total reward: 22.0 Training loss: 46.9463 Explore P: 0.4280\n",
      "Episode: 292 Steps: 21 Total reward: 22.0 Training loss: 19.2430 Explore P: 0.4271\n",
      "Episode: 293 Steps: 11 Total reward: 12.0 Training loss: 85.5534 Explore P: 0.4266\n",
      "Episode: 294 Steps: 16 Total reward: 17.0 Training loss: 17.6705 Explore P: 0.4259\n",
      "Episode: 295 Steps: 26 Total reward: 27.0 Training loss: 0.6895 Explore P: 0.4247\n",
      "Episode: 296 Steps: 36 Total reward: 37.0 Training loss: 14.4601 Explore P: 0.4231\n",
      "Episode: 297 Steps: 38 Total reward: 39.0 Training loss: 0.7137 Explore P: 0.4215\n",
      "Episode: 298 Steps: 12 Total reward: 13.0 Training loss: 18.3174 Explore P: 0.4210\n",
      "Episode: 299 Steps: 66 Total reward: 67.0 Training loss: 1.0240 Explore P: 0.4182\n",
      "Episode: 300 Steps: 70 Total reward: 71.0 Training loss: 0.7643 Explore P: 0.4152\n",
      "Episode: 301 Steps: 26 Total reward: 27.0 Training loss: 0.7582 Explore P: 0.4141\n",
      "Episode: 302 Steps: 198 Total reward: 199.0 Training loss: 1.0092 Explore P: 0.4059\n",
      "Episode: 303 Steps: 51 Total reward: 52.0 Training loss: 21.4627 Explore P: 0.4038\n",
      "Episode: 304 Steps: 30 Total reward: 31.0 Training loss: 0.8793 Explore P: 0.4026\n",
      "Episode: 305 Steps: 41 Total reward: 42.0 Training loss: 38.4694 Explore P: 0.4009\n",
      "Episode: 306 Steps: 33 Total reward: 34.0 Training loss: 48.1236 Explore P: 0.3996\n",
      "Episode: 307 Steps: 29 Total reward: 30.0 Training loss: 0.7343 Explore P: 0.3984\n",
      "Episode: 308 Steps: 77 Total reward: 78.0 Training loss: 29.4784 Explore P: 0.3953\n",
      "Episode: 309 Steps: 73 Total reward: 74.0 Training loss: 77.8375 Explore P: 0.3924\n",
      "Episode: 310 Steps: 30 Total reward: 31.0 Training loss: 0.8094 Explore P: 0.3912\n",
      "Episode: 311 Steps: 59 Total reward: 60.0 Training loss: 0.8312 Explore P: 0.3888\n",
      "Episode: 312 Steps: 36 Total reward: 37.0 Training loss: 22.0927 Explore P: 0.3874\n",
      "Episode: 313 Steps: 52 Total reward: 53.0 Training loss: 0.8286 Explore P: 0.3854\n",
      "Episode: 314 Steps: 40 Total reward: 41.0 Training loss: 0.9152 Explore P: 0.3838\n",
      "Episode: 315 Steps: 38 Total reward: 39.0 Training loss: 25.3550 Explore P: 0.3823\n",
      "Episode: 316 Steps: 36 Total reward: 37.0 Training loss: 36.4699 Explore P: 0.3809\n",
      "Episode: 317 Steps: 64 Total reward: 65.0 Training loss: 0.9551 Explore P: 0.3784\n",
      "Episode: 318 Steps: 91 Total reward: 92.0 Training loss: 0.9659 Explore P: 0.3750\n",
      "Episode: 319 Steps: 21 Total reward: 22.0 Training loss: 0.9509 Explore P: 0.3741\n",
      "Episode: 320 Steps: 150 Total reward: 151.0 Training loss: 17.2077 Explore P: 0.3685\n",
      "Episode: 321 Steps: 47 Total reward: 48.0 Training loss: 0.8535 Explore P: 0.3668\n",
      "Episode: 322 Steps: 54 Total reward: 55.0 Training loss: 0.5824 Explore P: 0.3648\n",
      "Episode: 323 Steps: 37 Total reward: 38.0 Training loss: 11.7708 Explore P: 0.3634\n",
      "Episode: 324 Steps: 33 Total reward: 34.0 Training loss: 1.2144 Explore P: 0.3622\n",
      "Episode: 325 Steps: 36 Total reward: 37.0 Training loss: 1.0820 Explore P: 0.3608\n",
      "Episode: 326 Steps: 33 Total reward: 34.0 Training loss: 50.2680 Explore P: 0.3596\n",
      "Episode: 327 Steps: 90 Total reward: 91.0 Training loss: 43.6655 Explore P: 0.3564\n",
      "Episode: 328 Steps: 98 Total reward: 99.0 Training loss: 0.5192 Explore P: 0.3529\n",
      "Episode: 329 Steps: 105 Total reward: 106.0 Training loss: 0.9987 Explore P: 0.3492\n",
      "Episode: 330 Steps: 37 Total reward: 38.0 Training loss: 1.2590 Explore P: 0.3478\n",
      "Episode: 331 Steps: 131 Total reward: 132.0 Training loss: 0.7681 Explore P: 0.3433\n",
      "Episode: 332 Steps: 49 Total reward: 50.0 Training loss: 18.8494 Explore P: 0.3416\n",
      "Episode: 333 Steps: 29 Total reward: 30.0 Training loss: 0.7790 Explore P: 0.3406\n",
      "Episode: 334 Steps: 74 Total reward: 75.0 Training loss: 1.0905 Explore P: 0.3380\n",
      "Episode: 335 Steps: 198 Total reward: 199.0 Training loss: 1.0241 Explore P: 0.3314\n",
      "Episode: 336 Steps: 66 Total reward: 67.0 Training loss: 0.8048 Explore P: 0.3292\n",
      "Episode: 337 Steps: 86 Total reward: 87.0 Training loss: 33.5594 Explore P: 0.3263\n",
      "Episode: 338 Steps: 83 Total reward: 84.0 Training loss: 33.2788 Explore P: 0.3236\n",
      "Episode: 339 Steps: 61 Total reward: 62.0 Training loss: 1.4764 Explore P: 0.3216\n",
      "Episode: 340 Steps: 45 Total reward: 46.0 Training loss: 1.3710 Explore P: 0.3201\n",
      "Episode: 341 Steps: 75 Total reward: 76.0 Training loss: 0.6852 Explore P: 0.3177\n",
      "Episode: 342 Steps: 37 Total reward: 38.0 Training loss: 1.0439 Explore P: 0.3165\n",
      "Episode: 343 Steps: 31 Total reward: 32.0 Training loss: 1.1218 Explore P: 0.3155\n",
      "Episode: 344 Steps: 54 Total reward: 55.0 Training loss: 77.4185 Explore P: 0.3138\n",
      "Episode: 345 Steps: 85 Total reward: 86.0 Training loss: 17.6597 Explore P: 0.3111\n",
      "Episode: 346 Steps: 110 Total reward: 111.0 Training loss: 16.9946 Explore P: 0.3077\n",
      "Episode: 347 Steps: 27 Total reward: 28.0 Training loss: 125.3910 Explore P: 0.3068\n",
      "Episode: 348 Steps: 134 Total reward: 135.0 Training loss: 0.9054 Explore P: 0.3027\n",
      "Episode: 349 Steps: 90 Total reward: 91.0 Training loss: 76.3661 Explore P: 0.3000\n",
      "Episode: 350 Steps: 99 Total reward: 100.0 Training loss: 0.7090 Explore P: 0.2970\n",
      "Episode: 351 Steps: 114 Total reward: 115.0 Training loss: 21.3051 Explore P: 0.2936\n",
      "Episode: 352 Steps: 58 Total reward: 59.0 Training loss: 1.3120 Explore P: 0.2919\n",
      "Episode: 353 Steps: 44 Total reward: 45.0 Training loss: 17.8440 Explore P: 0.2906\n",
      "Episode: 354 Steps: 96 Total reward: 97.0 Training loss: 0.9949 Explore P: 0.2878\n",
      "Episode: 355 Steps: 41 Total reward: 42.0 Training loss: 0.6821 Explore P: 0.2866\n",
      "Episode: 356 Steps: 120 Total reward: 121.0 Training loss: 103.5930 Explore P: 0.2832\n",
      "Episode: 357 Steps: 188 Total reward: 189.0 Training loss: 0.7554 Explore P: 0.2779\n",
      "Episode: 358 Steps: 100 Total reward: 101.0 Training loss: 45.1629 Explore P: 0.2751\n",
      "Episode: 359 Steps: 106 Total reward: 107.0 Training loss: 75.2434 Explore P: 0.2722\n",
      "Episode: 360 Steps: 115 Total reward: 116.0 Training loss: 0.7459 Explore P: 0.2691\n",
      "Episode: 361 Steps: 120 Total reward: 121.0 Training loss: 19.4507 Explore P: 0.2658\n",
      "Episode: 362 Steps: 105 Total reward: 106.0 Training loss: 0.8139 Explore P: 0.2631\n",
      "Episode: 363 Steps: 125 Total reward: 126.0 Training loss: 23.9459 Explore P: 0.2598\n",
      "Episode: 364 Steps: 194 Total reward: 195.0 Training loss: 52.1747 Explore P: 0.2548\n",
      "Episode: 365 Steps: 80 Total reward: 81.0 Training loss: 1.3912 Explore P: 0.2527\n",
      "Episode: 366 Steps: 77 Total reward: 78.0 Training loss: 30.0018 Explore P: 0.2508\n",
      "Episode: 367 Steps: 127 Total reward: 128.0 Training loss: 0.9991 Explore P: 0.2476\n",
      "Episode: 368 Steps: 111 Total reward: 112.0 Training loss: 0.7906 Explore P: 0.2449\n",
      "Episode: 369 Steps: 198 Total reward: 199.0 Training loss: 22.4016 Explore P: 0.2400\n",
      "Episode: 370 Steps: 102 Total reward: 103.0 Training loss: 18.5653 Explore P: 0.2376\n",
      "Episode: 371 Steps: 139 Total reward: 140.0 Training loss: 1.7673 Explore P: 0.2343\n",
      "Episode: 372 Steps: 93 Total reward: 94.0 Training loss: 1.2650 Explore P: 0.2321\n",
      "Episode: 373 Steps: 160 Total reward: 161.0 Training loss: 1.0688 Explore P: 0.2284\n",
      "Episode: 374 Steps: 135 Total reward: 136.0 Training loss: 136.4510 Explore P: 0.2254\n",
      "Episode: 375 Steps: 198 Total reward: 199.0 Training loss: 0.7765 Explore P: 0.2209\n",
      "Episode: 376 Steps: 137 Total reward: 138.0 Training loss: 1.5658 Explore P: 0.2179\n",
      "Episode: 377 Steps: 179 Total reward: 180.0 Training loss: 0.3765 Explore P: 0.2141\n",
      "Episode: 378 Steps: 108 Total reward: 109.0 Training loss: 1.0542 Explore P: 0.2117\n",
      "Episode: 379 Steps: 136 Total reward: 137.0 Training loss: 1.7362 Explore P: 0.2089\n",
      "Episode: 380 Steps: 155 Total reward: 156.0 Training loss: 1.4947 Explore P: 0.2057\n",
      "Episode: 381 Steps: 198 Total reward: 199.0 Training loss: 27.7165 Explore P: 0.2016\n",
      "Episode: 382 Steps: 156 Total reward: 157.0 Training loss: 0.7970 Explore P: 0.1985\n",
      "Episode: 383 Steps: 139 Total reward: 140.0 Training loss: 1.8948 Explore P: 0.1958\n",
      "Episode: 384 Steps: 198 Total reward: 199.0 Training loss: 0.8944 Explore P: 0.1919\n",
      "Episode: 385 Steps: 198 Total reward: 199.0 Training loss: 1.7244 Explore P: 0.1882\n",
      "Episode: 386 Steps: 198 Total reward: 199.0 Training loss: 0.8460 Explore P: 0.1845\n",
      "Episode: 387 Steps: 198 Total reward: 199.0 Training loss: 1.6745 Explore P: 0.1809\n",
      "Episode: 388 Steps: 151 Total reward: 152.0 Training loss: 1.2373 Explore P: 0.1781\n",
      "Episode: 389 Steps: 71 Total reward: 72.0 Training loss: 1.4385 Explore P: 0.1769\n",
      "Episode: 390 Steps: 159 Total reward: 160.0 Training loss: 1.3538 Explore P: 0.1741\n",
      "Episode: 391 Steps: 144 Total reward: 145.0 Training loss: 0.9340 Explore P: 0.1716\n",
      "Episode: 392 Steps: 198 Total reward: 199.0 Training loss: 0.9759 Explore P: 0.1682\n",
      "Episode: 393 Steps: 123 Total reward: 124.0 Training loss: 59.7298 Explore P: 0.1662\n",
      "Episode: 394 Steps: 112 Total reward: 113.0 Training loss: 1.5651 Explore P: 0.1643\n",
      "Episode: 395 Steps: 52 Total reward: 53.0 Training loss: 161.4159 Explore P: 0.1634\n",
      "Episode: 396 Steps: 54 Total reward: 55.0 Training loss: 2.5341 Explore P: 0.1626\n",
      "Episode: 397 Steps: 122 Total reward: 123.0 Training loss: 1.4126 Explore P: 0.1606\n",
      "Episode: 398 Steps: 198 Total reward: 199.0 Training loss: 48.4708 Explore P: 0.1574\n",
      "Episode: 399 Steps: 198 Total reward: 199.0 Training loss: 1.1025 Explore P: 0.1544\n",
      "Episode: 400 Steps: 198 Total reward: 199.0 Training loss: 1.0900 Explore P: 0.1513\n",
      "Episode: 401 Steps: 198 Total reward: 199.0 Training loss: 1.7037 Explore P: 0.1484\n",
      "Episode: 402 Steps: 198 Total reward: 199.0 Training loss: 0.8856 Explore P: 0.1455\n",
      "Episode: 403 Steps: 157 Total reward: 158.0 Training loss: 0.7055 Explore P: 0.1432\n",
      "Episode: 404 Steps: 144 Total reward: 145.0 Training loss: 0.9014 Explore P: 0.1412\n",
      "Episode: 405 Steps: 167 Total reward: 168.0 Training loss: 1.2339 Explore P: 0.1388\n",
      "Episode: 406 Steps: 171 Total reward: 172.0 Training loss: 1.5278 Explore P: 0.1365\n",
      "Episode: 407 Steps: 143 Total reward: 144.0 Training loss: 1.2918 Explore P: 0.1345\n",
      "Episode: 408 Steps: 156 Total reward: 157.0 Training loss: 0.8189 Explore P: 0.1325\n",
      "Episode: 409 Steps: 155 Total reward: 156.0 Training loss: 257.2232 Explore P: 0.1304\n",
      "Episode: 410 Steps: 195 Total reward: 196.0 Training loss: 2.4208 Explore P: 0.1279\n",
      "Episode: 411 Steps: 198 Total reward: 199.0 Training loss: 0.7184 Explore P: 0.1254\n",
      "Episode: 412 Steps: 109 Total reward: 110.0 Training loss: 1.4462 Explore P: 0.1240\n",
      "Episode: 413 Steps: 198 Total reward: 199.0 Training loss: 1.0308 Explore P: 0.1216\n",
      "Episode: 414 Steps: 198 Total reward: 199.0 Training loss: 0.9871 Explore P: 0.1192\n",
      "Episode: 415 Steps: 198 Total reward: 199.0 Training loss: 0.2116 Explore P: 0.1169\n",
      "Episode: 416 Steps: 198 Total reward: 199.0 Training loss: 197.3130 Explore P: 0.1146\n",
      "Episode: 417 Steps: 198 Total reward: 199.0 Training loss: 0.9162 Explore P: 0.1124\n",
      "Episode: 418 Steps: 198 Total reward: 199.0 Training loss: 203.0544 Explore P: 0.1102\n",
      "Episode: 419 Steps: 198 Total reward: 199.0 Training loss: 0.6181 Explore P: 0.1080\n",
      "Episode: 420 Steps: 198 Total reward: 199.0 Training loss: 0.6446 Explore P: 0.1059\n",
      "Episode: 421 Steps: 198 Total reward: 199.0 Training loss: 0.7763 Explore P: 0.1039\n",
      "Episode: 422 Steps: 198 Total reward: 199.0 Training loss: 0.3952 Explore P: 0.1018\n",
      "Episode: 423 Steps: 198 Total reward: 199.0 Training loss: 0.7945 Explore P: 0.0999\n",
      "Episode: 424 Steps: 198 Total reward: 199.0 Training loss: 0.4129 Explore P: 0.0979\n",
      "Episode: 425 Steps: 198 Total reward: 199.0 Training loss: 0.5764 Explore P: 0.0960\n",
      "Episode: 426 Steps: 198 Total reward: 199.0 Training loss: 0.5482 Explore P: 0.0941\n",
      "Episode: 427 Steps: 198 Total reward: 199.0 Training loss: 0.7179 Explore P: 0.0923\n",
      "Episode: 428 Steps: 198 Total reward: 199.0 Training loss: 0.4623 Explore P: 0.0905\n",
      "Episode: 429 Steps: 198 Total reward: 199.0 Training loss: 0.4704 Explore P: 0.0887\n",
      "Episode: 430 Steps: 198 Total reward: 199.0 Training loss: 1.3357 Explore P: 0.0870\n",
      "Episode: 431 Steps: 161 Total reward: 162.0 Training loss: 0.2746 Explore P: 0.0856\n",
      "Episode: 432 Steps: 198 Total reward: 199.0 Training loss: 0.3568 Explore P: 0.0840\n",
      "Episode: 433 Steps: 139 Total reward: 140.0 Training loss: 0.4598 Explore P: 0.0828\n",
      "Episode: 434 Steps: 198 Total reward: 199.0 Training loss: 127.9606 Explore P: 0.0812\n",
      "Episode: 435 Steps: 198 Total reward: 199.0 Training loss: 0.4778 Explore P: 0.0796\n",
      "Episode: 436 Steps: 198 Total reward: 199.0 Training loss: 0.2706 Explore P: 0.0781\n",
      "Episode: 437 Steps: 156 Total reward: 157.0 Training loss: 0.4063 Explore P: 0.0769\n",
      "Episode: 438 Steps: 198 Total reward: 199.0 Training loss: 0.6616 Explore P: 0.0754\n",
      "Episode: 439 Steps: 185 Total reward: 186.0 Training loss: 0.4141 Explore P: 0.0740\n",
      "Episode: 440 Steps: 85 Total reward: 86.0 Training loss: 0.4509 Explore P: 0.0734\n",
      "Episode: 441 Steps: 93 Total reward: 94.0 Training loss: 0.4305 Explore P: 0.0727\n",
      "Episode: 442 Steps: 86 Total reward: 87.0 Training loss: 0.3199 Explore P: 0.0721\n",
      "Episode: 443 Steps: 182 Total reward: 183.0 Training loss: 0.5752 Explore P: 0.0708\n",
      "Episode: 444 Steps: 98 Total reward: 99.0 Training loss: 0.3396 Explore P: 0.0701\n",
      "Episode: 445 Steps: 198 Total reward: 199.0 Training loss: 216.5995 Explore P: 0.0687\n",
      "Episode: 446 Steps: 97 Total reward: 98.0 Training loss: 0.1608 Explore P: 0.0681\n",
      "Episode: 447 Steps: 122 Total reward: 123.0 Training loss: 0.1745 Explore P: 0.0673\n",
      "Episode: 448 Steps: 164 Total reward: 165.0 Training loss: 0.2335 Explore P: 0.0662\n",
      "Episode: 449 Steps: 94 Total reward: 95.0 Training loss: 0.2792 Explore P: 0.0656\n",
      "Episode: 450 Steps: 87 Total reward: 88.0 Training loss: 0.1107 Explore P: 0.0650\n",
      "Episode: 451 Steps: 154 Total reward: 155.0 Training loss: 0.2229 Explore P: 0.0640\n",
      "Episode: 452 Steps: 113 Total reward: 114.0 Training loss: 0.2308 Explore P: 0.0633\n",
      "Episode: 453 Steps: 90 Total reward: 91.0 Training loss: 0.2916 Explore P: 0.0627\n",
      "Episode: 454 Steps: 135 Total reward: 136.0 Training loss: 0.2323 Explore P: 0.0619\n",
      "Episode: 455 Steps: 128 Total reward: 129.0 Training loss: 48.9850 Explore P: 0.0611\n",
      "Episode: 456 Steps: 75 Total reward: 76.0 Training loss: 0.4344 Explore P: 0.0607\n",
      "Episode: 457 Steps: 94 Total reward: 95.0 Training loss: 0.7513 Explore P: 0.0601\n",
      "Episode: 458 Steps: 50 Total reward: 51.0 Training loss: 0.4829 Explore P: 0.0598\n",
      "Episode: 459 Steps: 105 Total reward: 106.0 Training loss: 0.9139 Explore P: 0.0592\n",
      "Episode: 460 Steps: 76 Total reward: 77.0 Training loss: 0.1233 Explore P: 0.0587\n",
      "Episode: 461 Steps: 198 Total reward: 199.0 Training loss: 0.4544 Explore P: 0.0576\n",
      "Episode: 462 Steps: 58 Total reward: 59.0 Training loss: 0.3854 Explore P: 0.0573\n",
      "Episode: 463 Steps: 87 Total reward: 88.0 Training loss: 0.2230 Explore P: 0.0568\n",
      "Episode: 464 Steps: 72 Total reward: 73.0 Training loss: 0.4816 Explore P: 0.0564\n",
      "Episode: 465 Steps: 198 Total reward: 199.0 Training loss: 0.2362 Explore P: 0.0553\n",
      "Episode: 466 Steps: 198 Total reward: 199.0 Training loss: 0.1575 Explore P: 0.0542\n",
      "Episode: 467 Steps: 81 Total reward: 82.0 Training loss: 0.1904 Explore P: 0.0538\n",
      "Episode: 468 Steps: 198 Total reward: 199.0 Training loss: 0.3420 Explore P: 0.0527\n",
      "Episode: 469 Steps: 198 Total reward: 199.0 Training loss: 0.1357 Explore P: 0.0517\n",
      "Episode: 470 Steps: 198 Total reward: 199.0 Training loss: 0.3328 Explore P: 0.0507\n",
      "Episode: 471 Steps: 102 Total reward: 103.0 Training loss: 0.1757 Explore P: 0.0502\n",
      "Episode: 472 Steps: 198 Total reward: 199.0 Training loss: 0.2103 Explore P: 0.0492\n",
      "Episode: 473 Steps: 164 Total reward: 165.0 Training loss: 0.2113 Explore P: 0.0484\n",
      "Episode: 474 Steps: 93 Total reward: 94.0 Training loss: 0.3097 Explore P: 0.0480\n",
      "Episode: 475 Steps: 81 Total reward: 82.0 Training loss: 0.2564 Explore P: 0.0476\n",
      "Episode: 476 Steps: 198 Total reward: 199.0 Training loss: 0.4343 Explore P: 0.0467\n",
      "Episode: 477 Steps: 198 Total reward: 199.0 Training loss: 0.2504 Explore P: 0.0458\n",
      "Episode: 478 Steps: 198 Total reward: 199.0 Training loss: 0.1756 Explore P: 0.0449\n",
      "Episode: 479 Steps: 198 Total reward: 199.0 Training loss: 27.6504 Explore P: 0.0440\n",
      "Episode: 480 Steps: 198 Total reward: 199.0 Training loss: 0.6044 Explore P: 0.0432\n",
      "Episode: 481 Steps: 198 Total reward: 199.0 Training loss: 0.2155 Explore P: 0.0424\n",
      "Episode: 482 Steps: 198 Total reward: 199.0 Training loss: 0.3200 Explore P: 0.0415\n",
      "Episode: 483 Steps: 198 Total reward: 199.0 Training loss: 0.4813 Explore P: 0.0407\n",
      "Episode: 484 Steps: 198 Total reward: 199.0 Training loss: 0.3408 Explore P: 0.0400\n",
      "Episode: 485 Steps: 198 Total reward: 199.0 Training loss: 0.5614 Explore P: 0.0392\n",
      "Episode: 486 Steps: 198 Total reward: 199.0 Training loss: 0.2835 Explore P: 0.0384\n",
      "Episode: 487 Steps: 198 Total reward: 199.0 Training loss: 0.1429 Explore P: 0.0377\n",
      "Episode: 488 Steps: 198 Total reward: 199.0 Training loss: 0.2807 Explore P: 0.0370\n",
      "Episode: 489 Steps: 198 Total reward: 199.0 Training loss: 0.3386 Explore P: 0.0363\n",
      "Episode: 490 Steps: 156 Total reward: 157.0 Training loss: 0.1934 Explore P: 0.0357\n",
      "Episode: 491 Steps: 191 Total reward: 192.0 Training loss: 0.2995 Explore P: 0.0351\n",
      "Episode: 492 Steps: 165 Total reward: 166.0 Training loss: 0.1542 Explore P: 0.0345\n",
      "Episode: 493 Steps: 198 Total reward: 199.0 Training loss: 0.3974 Explore P: 0.0338\n",
      "Episode: 494 Steps: 137 Total reward: 138.0 Training loss: 0.4312 Explore P: 0.0334\n",
      "Episode: 495 Steps: 172 Total reward: 173.0 Training loss: 0.2291 Explore P: 0.0328\n",
      "Episode: 496 Steps: 110 Total reward: 111.0 Training loss: 0.3665 Explore P: 0.0325\n",
      "Episode: 497 Steps: 129 Total reward: 130.0 Training loss: 0.3853 Explore P: 0.0321\n",
      "Episode: 498 Steps: 142 Total reward: 143.0 Training loss: 0.5915 Explore P: 0.0316\n",
      "Episode: 499 Steps: 135 Total reward: 136.0 Training loss: 0.2620 Explore P: 0.0312\n",
      "Episode: 500 Steps: 146 Total reward: 147.0 Training loss: 0.4461 Explore P: 0.0308\n",
      "Episode: 501 Steps: 104 Total reward: 105.0 Training loss: 0.2753 Explore P: 0.0305\n",
      "Episode: 502 Steps: 123 Total reward: 124.0 Training loss: 294.2188 Explore P: 0.0301\n",
      "Episode: 503 Steps: 111 Total reward: 112.0 Training loss: 0.4750 Explore P: 0.0298\n",
      "Episode: 504 Steps: 107 Total reward: 108.0 Training loss: 437.1273 Explore P: 0.0295\n",
      "Episode: 505 Steps: 112 Total reward: 113.0 Training loss: 0.3070 Explore P: 0.0292\n",
      "Episode: 506 Steps: 32 Total reward: 33.0 Training loss: 0.7154 Explore P: 0.0291\n",
      "Episode: 507 Steps: 31 Total reward: 32.0 Training loss: 0.4494 Explore P: 0.0290\n",
      "Episode: 508 Steps: 46 Total reward: 47.0 Training loss: 249.8338 Explore P: 0.0288\n",
      "Episode: 509 Steps: 42 Total reward: 43.0 Training loss: 0.5325 Explore P: 0.0287\n",
      "Episode: 510 Steps: 103 Total reward: 104.0 Training loss: 248.1574 Explore P: 0.0284\n",
      "Episode: 511 Steps: 40 Total reward: 41.0 Training loss: 0.7037 Explore P: 0.0283\n",
      "Episode: 512 Steps: 36 Total reward: 37.0 Training loss: 0.4087 Explore P: 0.0282\n",
      "Episode: 513 Steps: 34 Total reward: 35.0 Training loss: 0.7535 Explore P: 0.0281\n",
      "Episode: 514 Steps: 105 Total reward: 106.0 Training loss: 0.8119 Explore P: 0.0278\n",
      "Episode: 515 Steps: 28 Total reward: 29.0 Training loss: 0.5624 Explore P: 0.0278\n",
      "Episode: 516 Steps: 32 Total reward: 33.0 Training loss: 258.3838 Explore P: 0.0277\n",
      "Episode: 517 Steps: 25 Total reward: 26.0 Training loss: 0.8376 Explore P: 0.0276\n",
      "Episode: 518 Steps: 22 Total reward: 23.0 Training loss: 621.6479 Explore P: 0.0275\n",
      "Episode: 519 Steps: 17 Total reward: 18.0 Training loss: 1.2334 Explore P: 0.0275\n",
      "Episode: 520 Steps: 18 Total reward: 19.0 Training loss: 1.2779 Explore P: 0.0274\n",
      "Episode: 521 Steps: 19 Total reward: 20.0 Training loss: 1.5031 Explore P: 0.0274\n",
      "Episode: 522 Steps: 17 Total reward: 18.0 Training loss: 1.5894 Explore P: 0.0273\n",
      "Episode: 523 Steps: 19 Total reward: 20.0 Training loss: 223.9511 Explore P: 0.0273\n",
      "Episode: 524 Steps: 20 Total reward: 21.0 Training loss: 0.6812 Explore P: 0.0272\n",
      "Episode: 525 Steps: 29 Total reward: 30.0 Training loss: 0.8048 Explore P: 0.0272\n",
      "Episode: 526 Steps: 32 Total reward: 33.0 Training loss: 0.4450 Explore P: 0.0271\n",
      "Episode: 527 Steps: 97 Total reward: 98.0 Training loss: 1.0142 Explore P: 0.0268\n",
      "Episode: 528 Steps: 25 Total reward: 26.0 Training loss: 722.8300 Explore P: 0.0268\n",
      "Episode: 529 Steps: 26 Total reward: 27.0 Training loss: 0.5268 Explore P: 0.0267\n",
      "Episode: 530 Steps: 35 Total reward: 36.0 Training loss: 0.7770 Explore P: 0.0266\n",
      "Episode: 531 Steps: 35 Total reward: 36.0 Training loss: 0.5093 Explore P: 0.0265\n",
      "Episode: 532 Steps: 28 Total reward: 29.0 Training loss: 0.8070 Explore P: 0.0264\n",
      "Episode: 533 Steps: 31 Total reward: 32.0 Training loss: 1.0028 Explore P: 0.0263\n",
      "Episode: 534 Steps: 28 Total reward: 29.0 Training loss: 0.8125 Explore P: 0.0263\n",
      "Episode: 535 Steps: 20 Total reward: 21.0 Training loss: 0.7242 Explore P: 0.0262\n",
      "Episode: 536 Steps: 28 Total reward: 29.0 Training loss: 0.5222 Explore P: 0.0261\n",
      "Episode: 537 Steps: 22 Total reward: 23.0 Training loss: 1.5422 Explore P: 0.0261\n",
      "Episode: 538 Steps: 20 Total reward: 21.0 Training loss: 1.1601 Explore P: 0.0260\n",
      "Episode: 539 Steps: 29 Total reward: 30.0 Training loss: 0.5640 Explore P: 0.0260\n",
      "Episode: 540 Steps: 27 Total reward: 28.0 Training loss: 0.7486 Explore P: 0.0259\n",
      "Episode: 541 Steps: 24 Total reward: 25.0 Training loss: 1.1712 Explore P: 0.0258\n",
      "Episode: 542 Steps: 33 Total reward: 34.0 Training loss: 0.9030 Explore P: 0.0257\n",
      "Episode: 543 Steps: 19 Total reward: 20.0 Training loss: 1.3855 Explore P: 0.0257\n",
      "Episode: 544 Steps: 24 Total reward: 25.0 Training loss: 0.8147 Explore P: 0.0256\n",
      "Episode: 545 Steps: 28 Total reward: 29.0 Training loss: 0.9368 Explore P: 0.0256\n",
      "Episode: 546 Steps: 28 Total reward: 29.0 Training loss: 1.1173 Explore P: 0.0255\n",
      "Episode: 547 Steps: 22 Total reward: 23.0 Training loss: 1.2875 Explore P: 0.0254\n",
      "Episode: 548 Steps: 28 Total reward: 29.0 Training loss: 207.7197 Explore P: 0.0254\n",
      "Episode: 549 Steps: 28 Total reward: 29.0 Training loss: 0.7425 Explore P: 0.0253\n",
      "Episode: 550 Steps: 33 Total reward: 34.0 Training loss: 1.3740 Explore P: 0.0252\n",
      "Episode: 551 Steps: 29 Total reward: 30.0 Training loss: 0.5874 Explore P: 0.0251\n",
      "Episode: 552 Steps: 150 Total reward: 151.0 Training loss: 0.4008 Explore P: 0.0248\n",
      "Episode: 553 Steps: 143 Total reward: 144.0 Training loss: 1.1933 Explore P: 0.0244\n",
      "Episode: 554 Steps: 198 Total reward: 199.0 Training loss: 0.7003 Explore P: 0.0240\n",
      "Episode: 555 Steps: 198 Total reward: 199.0 Training loss: 1.3570 Explore P: 0.0235\n",
      "Episode: 556 Steps: 198 Total reward: 199.0 Training loss: 0.8863 Explore P: 0.0231\n",
      "Episode: 557 Steps: 198 Total reward: 199.0 Training loss: 0.4443 Explore P: 0.0226\n",
      "Episode: 558 Steps: 198 Total reward: 199.0 Training loss: 583.0622 Explore P: 0.0222\n",
      "Episode: 559 Steps: 198 Total reward: 199.0 Training loss: 59.0674 Explore P: 0.0218\n",
      "Episode: 560 Steps: 198 Total reward: 199.0 Training loss: 0.6573 Explore P: 0.0214\n",
      "Episode: 561 Steps: 198 Total reward: 199.0 Training loss: 0.6821 Explore P: 0.0210\n",
      "Episode: 562 Steps: 198 Total reward: 199.0 Training loss: 0.6570 Explore P: 0.0206\n",
      "Episode: 563 Steps: 198 Total reward: 199.0 Training loss: 0.4614 Explore P: 0.0202\n",
      "Episode: 564 Steps: 198 Total reward: 199.0 Training loss: 0.7492 Explore P: 0.0198\n",
      "Episode: 565 Steps: 198 Total reward: 199.0 Training loss: 1.1813 Explore P: 0.0195\n",
      "Episode: 566 Steps: 198 Total reward: 199.0 Training loss: 0.8606 Explore P: 0.0191\n",
      "Episode: 567 Steps: 198 Total reward: 199.0 Training loss: 96.0077 Explore P: 0.0187\n",
      "Episode: 568 Steps: 198 Total reward: 199.0 Training loss: 0.5528 Explore P: 0.0184\n",
      "Episode: 569 Steps: 198 Total reward: 199.0 Training loss: 0.8225 Explore P: 0.0180\n",
      "Episode: 570 Steps: 198 Total reward: 199.0 Training loss: 1.1632 Explore P: 0.0177\n",
      "Episode: 571 Steps: 198 Total reward: 199.0 Training loss: 0.5887 Explore P: 0.0174\n",
      "Episode: 572 Steps: 198 Total reward: 199.0 Training loss: 0.4985 Explore P: 0.0171\n",
      "Episode: 573 Steps: 197 Total reward: 198.0 Training loss: 0.5601 Explore P: 0.0167\n",
      "Episode: 574 Steps: 198 Total reward: 199.0 Training loss: 0.3865 Explore P: 0.0164\n",
      "Episode: 575 Steps: 198 Total reward: 199.0 Training loss: 0.8063 Explore P: 0.0161\n",
      "Episode: 576 Steps: 198 Total reward: 199.0 Training loss: 1.3878 Explore P: 0.0158\n",
      "Episode: 577 Steps: 198 Total reward: 199.0 Training loss: 0.4732 Explore P: 0.0155\n",
      "Episode: 578 Steps: 198 Total reward: 199.0 Training loss: 199.1308 Explore P: 0.0153\n",
      "Episode: 579 Steps: 198 Total reward: 199.0 Training loss: 30.4437 Explore P: 0.0150\n",
      "Episode: 580 Steps: 198 Total reward: 199.0 Training loss: 0.4070 Explore P: 0.0147\n",
      "Episode: 581 Steps: 198 Total reward: 199.0 Training loss: 0.4855 Explore P: 0.0144\n",
      "Episode: 582 Steps: 198 Total reward: 199.0 Training loss: 0.3274 Explore P: 0.0142\n",
      "Episode: 583 Steps: 198 Total reward: 199.0 Training loss: 0.4925 Explore P: 0.0139\n",
      "Episode: 584 Steps: 198 Total reward: 199.0 Training loss: 0.6933 Explore P: 0.0136\n",
      "Episode: 585 Steps: 198 Total reward: 199.0 Training loss: 0.7171 Explore P: 0.0134\n",
      "Episode: 586 Steps: 198 Total reward: 199.0 Training loss: 0.7113 Explore P: 0.0132\n",
      "Episode: 587 Steps: 198 Total reward: 199.0 Training loss: 0.7828 Explore P: 0.0129\n",
      "Episode: 588 Steps: 198 Total reward: 199.0 Training loss: 0.7309 Explore P: 0.0127\n",
      "Episode: 589 Steps: 198 Total reward: 199.0 Training loss: 0.3885 Explore P: 0.0124\n",
      "Episode: 590 Steps: 198 Total reward: 199.0 Training loss: 0.8333 Explore P: 0.0122\n",
      "Episode: 591 Steps: 198 Total reward: 199.0 Training loss: 0.6129 Explore P: 0.0120\n",
      "Episode: 592 Steps: 198 Total reward: 199.0 Training loss: 0.4871 Explore P: 0.0118\n",
      "Episode: 593 Steps: 198 Total reward: 199.0 Training loss: 0.7436 Explore P: 0.0116\n",
      "Episode: 594 Steps: 198 Total reward: 199.0 Training loss: 0.6602 Explore P: 0.0114\n",
      "Episode: 595 Steps: 198 Total reward: 199.0 Training loss: 0.4343 Explore P: 0.0112\n",
      "Episode: 596 Steps: 198 Total reward: 199.0 Training loss: 0.4988 Explore P: 0.0110\n",
      "Episode: 597 Steps: 198 Total reward: 199.0 Training loss: 0.5981 Explore P: 0.0108\n",
      "Episode: 598 Steps: 198 Total reward: 199.0 Training loss: 0.2664 Explore P: 0.0106\n",
      "Episode: 599 Steps: 198 Total reward: 199.0 Training loss: 218.4274 Explore P: 0.0104\n",
      "Episode: 600 Steps: 198 Total reward: 199.0 Training loss: 221.6697 Explore P: 0.0102\n",
      "Episode: 601 Steps: 198 Total reward: 199.0 Training loss: 0.5180 Explore P: 0.0100\n",
      "Episode: 602 Steps: 198 Total reward: 199.0 Training loss: 0.4856 Explore P: 0.0098\n",
      "Episode: 603 Steps: 198 Total reward: 199.0 Training loss: 210.3976 Explore P: 0.0097\n",
      "Episode: 604 Steps: 198 Total reward: 199.0 Training loss: 0.2880 Explore P: 0.0095\n",
      "Episode: 605 Steps: 198 Total reward: 199.0 Training loss: 0.2904 Explore P: 0.0093\n",
      "Episode: 606 Steps: 198 Total reward: 199.0 Training loss: 0.2430 Explore P: 0.0092\n",
      "Episode: 607 Steps: 198 Total reward: 199.0 Training loss: 0.2447 Explore P: 0.0090\n",
      "Episode: 608 Steps: 198 Total reward: 199.0 Training loss: 215.6176 Explore P: 0.0088\n",
      "Episode: 609 Steps: 198 Total reward: 199.0 Training loss: 0.2910 Explore P: 0.0087\n",
      "Episode: 610 Steps: 198 Total reward: 199.0 Training loss: 0.1233 Explore P: 0.0085\n",
      "Episode: 611 Steps: 198 Total reward: 199.0 Training loss: 200.7571 Explore P: 0.0084\n",
      "Episode: 612 Steps: 198 Total reward: 199.0 Training loss: 0.4261 Explore P: 0.0082\n",
      "Episode: 613 Steps: 198 Total reward: 199.0 Training loss: 0.4000 Explore P: 0.0081\n",
      "Episode: 614 Steps: 198 Total reward: 199.0 Training loss: 0.2322 Explore P: 0.0080\n",
      "Episode: 615 Steps: 198 Total reward: 199.0 Training loss: 0.2396 Explore P: 0.0078\n",
      "Episode: 616 Steps: 198 Total reward: 199.0 Training loss: 0.3696 Explore P: 0.0077\n",
      "Episode: 617 Steps: 198 Total reward: 199.0 Training loss: 0.1773 Explore P: 0.0076\n",
      "Episode: 618 Steps: 198 Total reward: 199.0 Training loss: 0.2448 Explore P: 0.0074\n",
      "Episode: 619 Steps: 198 Total reward: 199.0 Training loss: 0.2594 Explore P: 0.0073\n",
      "Episode: 620 Steps: 198 Total reward: 199.0 Training loss: 0.2061 Explore P: 0.0072\n",
      "Episode: 621 Steps: 198 Total reward: 199.0 Training loss: 0.4390 Explore P: 0.0071\n",
      "Episode: 622 Steps: 198 Total reward: 199.0 Training loss: 0.3326 Explore P: 0.0069\n",
      "Episode: 623 Steps: 198 Total reward: 199.0 Training loss: 0.2137 Explore P: 0.0068\n",
      "Episode: 624 Steps: 198 Total reward: 199.0 Training loss: 0.2282 Explore P: 0.0067\n",
      "Episode: 625 Steps: 198 Total reward: 199.0 Training loss: 0.2615 Explore P: 0.0066\n",
      "Episode: 626 Steps: 198 Total reward: 199.0 Training loss: 0.2589 Explore P: 0.0065\n",
      "Episode: 627 Steps: 198 Total reward: 199.0 Training loss: 0.2166 Explore P: 0.0064\n",
      "Episode: 628 Steps: 198 Total reward: 199.0 Training loss: 0.2889 Explore P: 0.0063\n",
      "Episode: 629 Steps: 198 Total reward: 199.0 Training loss: 0.3213 Explore P: 0.0062\n",
      "Episode: 630 Steps: 198 Total reward: 199.0 Training loss: 0.2427 Explore P: 0.0061\n",
      "Episode: 631 Steps: 198 Total reward: 199.0 Training loss: 189.1459 Explore P: 0.0060\n",
      "Episode: 632 Steps: 198 Total reward: 199.0 Training loss: 0.3054 Explore P: 0.0059\n",
      "Episode: 633 Steps: 198 Total reward: 199.0 Training loss: 0.3499 Explore P: 0.0058\n",
      "Episode: 634 Steps: 198 Total reward: 199.0 Training loss: 0.1549 Explore P: 0.0057\n",
      "Episode: 635 Steps: 198 Total reward: 199.0 Training loss: 0.1794 Explore P: 0.0056\n",
      "Episode: 636 Steps: 198 Total reward: 199.0 Training loss: 0.3701 Explore P: 0.0055\n",
      "Episode: 637 Steps: 198 Total reward: 199.0 Training loss: 246.5319 Explore P: 0.0054\n",
      "Episode: 638 Steps: 198 Total reward: 199.0 Training loss: 0.2240 Explore P: 0.0053\n",
      "Episode: 639 Steps: 198 Total reward: 199.0 Training loss: 0.2578 Explore P: 0.0052\n",
      "Episode: 640 Steps: 198 Total reward: 199.0 Training loss: 0.3082 Explore P: 0.0051\n",
      "Episode: 641 Steps: 198 Total reward: 199.0 Training loss: 0.4076 Explore P: 0.0051\n",
      "Episode: 642 Steps: 198 Total reward: 199.0 Training loss: 0.2320 Explore P: 0.0050\n",
      "Episode: 643 Steps: 198 Total reward: 199.0 Training loss: 0.2353 Explore P: 0.0049\n",
      "Episode: 644 Steps: 198 Total reward: 199.0 Training loss: 0.1528 Explore P: 0.0048\n",
      "Episode: 645 Steps: 198 Total reward: 199.0 Training loss: 0.3039 Explore P: 0.0048\n",
      "Episode: 646 Steps: 198 Total reward: 199.0 Training loss: 0.1748 Explore P: 0.0047\n",
      "Episode: 647 Steps: 198 Total reward: 199.0 Training loss: 0.2472 Explore P: 0.0046\n",
      "Episode: 648 Steps: 198 Total reward: 199.0 Training loss: 0.2505 Explore P: 0.0045\n",
      "Episode: 649 Steps: 198 Total reward: 199.0 Training loss: 0.1675 Explore P: 0.0045\n",
      "Episode: 650 Steps: 198 Total reward: 199.0 Training loss: 0.3471 Explore P: 0.0044\n",
      "Episode: 651 Steps: 198 Total reward: 199.0 Training loss: 0.2034 Explore P: 0.0043\n",
      "Episode: 652 Steps: 198 Total reward: 199.0 Training loss: 0.2317 Explore P: 0.0043\n",
      "Episode: 653 Steps: 198 Total reward: 199.0 Training loss: 0.1803 Explore P: 0.0042\n",
      "Episode: 654 Steps: 198 Total reward: 199.0 Training loss: 0.1876 Explore P: 0.0041\n",
      "Episode: 655 Steps: 198 Total reward: 199.0 Training loss: 0.1761 Explore P: 0.0041\n",
      "Episode: 656 Steps: 198 Total reward: 199.0 Training loss: 0.2281 Explore P: 0.0040\n",
      "Episode: 657 Steps: 198 Total reward: 199.0 Training loss: 0.1124 Explore P: 0.0040\n",
      "Episode: 658 Steps: 198 Total reward: 199.0 Training loss: 0.2383 Explore P: 0.0039\n",
      "Episode: 659 Steps: 198 Total reward: 199.0 Training loss: 0.1603 Explore P: 0.0038\n",
      "Episode: 660 Steps: 198 Total reward: 199.0 Training loss: 0.2581 Explore P: 0.0038\n",
      "Episode: 661 Steps: 198 Total reward: 199.0 Training loss: 241.9783 Explore P: 0.0037\n",
      "Episode: 662 Steps: 198 Total reward: 199.0 Training loss: 0.2945 Explore P: 0.0037\n",
      "Episode: 663 Steps: 198 Total reward: 199.0 Training loss: 0.2346 Explore P: 0.0036\n",
      "Episode: 664 Steps: 198 Total reward: 199.0 Training loss: 0.3786 Explore P: 0.0036\n",
      "Episode: 665 Steps: 198 Total reward: 199.0 Training loss: 0.3485 Explore P: 0.0035\n",
      "Episode: 666 Steps: 198 Total reward: 199.0 Training loss: 0.2112 Explore P: 0.0035\n",
      "Episode: 667 Steps: 198 Total reward: 199.0 Training loss: 0.1889 Explore P: 0.0034\n",
      "Episode: 668 Steps: 198 Total reward: 199.0 Training loss: 0.2211 Explore P: 0.0034\n",
      "Episode: 669 Steps: 198 Total reward: 199.0 Training loss: 0.1597 Explore P: 0.0033\n",
      "Episode: 670 Steps: 198 Total reward: 199.0 Training loss: 0.1360 Explore P: 0.0033\n",
      "Episode: 671 Steps: 198 Total reward: 199.0 Training loss: 0.1798 Explore P: 0.0032\n",
      "Episode: 672 Steps: 198 Total reward: 199.0 Training loss: 0.2089 Explore P: 0.0032\n",
      "Episode: 673 Steps: 198 Total reward: 199.0 Training loss: 0.2294 Explore P: 0.0032\n",
      "Episode: 674 Steps: 198 Total reward: 199.0 Training loss: 294.8990 Explore P: 0.0031\n",
      "Episode: 675 Steps: 198 Total reward: 199.0 Training loss: 0.2285 Explore P: 0.0031\n",
      "Episode: 676 Steps: 198 Total reward: 199.0 Training loss: 0.5303 Explore P: 0.0030\n",
      "Episode: 677 Steps: 66 Total reward: 67.0 Training loss: 261.0100 Explore P: 0.0030\n",
      "Episode: 678 Steps: 99 Total reward: 100.0 Training loss: 0.5966 Explore P: 0.0030\n",
      "Episode: 679 Steps: 78 Total reward: 79.0 Training loss: 0.3803 Explore P: 0.0030\n",
      "Episode: 680 Steps: 77 Total reward: 78.0 Training loss: 0.4436 Explore P: 0.0030\n",
      "Episode: 681 Steps: 19 Total reward: 20.0 Training loss: 0.5623 Explore P: 0.0030\n",
      "Episode: 682 Steps: 16 Total reward: 17.0 Training loss: 0.7617 Explore P: 0.0030\n",
      "Episode: 683 Steps: 14 Total reward: 15.0 Training loss: 0.7235 Explore P: 0.0030\n",
      "Episode: 684 Steps: 12 Total reward: 13.0 Training loss: 0.7186 Explore P: 0.0029\n",
      "Episode: 685 Steps: 12 Total reward: 13.0 Training loss: 0.6735 Explore P: 0.0029\n",
      "Episode: 686 Steps: 12 Total reward: 13.0 Training loss: 0.5943 Explore P: 0.0029\n",
      "Episode: 687 Steps: 16 Total reward: 17.0 Training loss: 0.8527 Explore P: 0.0029\n",
      "Episode: 688 Steps: 11 Total reward: 12.0 Training loss: 0.7501 Explore P: 0.0029\n",
      "Episode: 689 Steps: 12 Total reward: 13.0 Training loss: 0.8717 Explore P: 0.0029\n",
      "Episode: 690 Steps: 13 Total reward: 14.0 Training loss: 0.8428 Explore P: 0.0029\n",
      "Episode: 691 Steps: 14 Total reward: 15.0 Training loss: 0.7379 Explore P: 0.0029\n",
      "Episode: 692 Steps: 13 Total reward: 14.0 Training loss: 0.7238 Explore P: 0.0029\n",
      "Episode: 693 Steps: 13 Total reward: 14.0 Training loss: 0.8736 Explore P: 0.0029\n",
      "Episode: 694 Steps: 18 Total reward: 19.0 Training loss: 0.5182 Explore P: 0.0029\n",
      "Episode: 695 Steps: 13 Total reward: 14.0 Training loss: 0.5871 Explore P: 0.0029\n",
      "Episode: 696 Steps: 15 Total reward: 16.0 Training loss: 0.4368 Explore P: 0.0029\n",
      "Episode: 697 Steps: 14 Total reward: 15.0 Training loss: 353.8049 Explore P: 0.0029\n",
      "Episode: 698 Steps: 20 Total reward: 21.0 Training loss: 0.3127 Explore P: 0.0029\n",
      "Episode: 699 Steps: 20 Total reward: 21.0 Training loss: 0.3319 Explore P: 0.0029\n",
      "Episode: 700 Steps: 18 Total reward: 19.0 Training loss: 0.3663 Explore P: 0.0029\n",
      "Episode: 701 Steps: 14 Total reward: 15.0 Training loss: 335.6339 Explore P: 0.0029\n",
      "Episode: 702 Steps: 12 Total reward: 13.0 Training loss: 0.9202 Explore P: 0.0029\n",
      "Episode: 703 Steps: 14 Total reward: 15.0 Training loss: 0.7574 Explore P: 0.0029\n",
      "Episode: 704 Steps: 13 Total reward: 14.0 Training loss: 278.3314 Explore P: 0.0029\n",
      "Episode: 705 Steps: 13 Total reward: 14.0 Training loss: 0.5727 Explore P: 0.0029\n",
      "Episode: 706 Steps: 14 Total reward: 15.0 Training loss: 0.6455 Explore P: 0.0029\n",
      "Episode: 707 Steps: 14 Total reward: 15.0 Training loss: 357.6800 Explore P: 0.0029\n",
      "Episode: 708 Steps: 11 Total reward: 12.0 Training loss: 1.2715 Explore P: 0.0029\n",
      "Episode: 709 Steps: 10 Total reward: 11.0 Training loss: 1.2811 Explore P: 0.0029\n",
      "Episode: 710 Steps: 9 Total reward: 10.0 Training loss: 1.6364 Explore P: 0.0029\n",
      "Episode: 711 Steps: 9 Total reward: 10.0 Training loss: 113.1969 Explore P: 0.0029\n",
      "Episode: 712 Steps: 12 Total reward: 13.0 Training loss: 277.5254 Explore P: 0.0029\n",
      "Episode: 713 Steps: 14 Total reward: 15.0 Training loss: 1.2172 Explore P: 0.0029\n",
      "Episode: 714 Steps: 23 Total reward: 24.0 Training loss: 338.1293 Explore P: 0.0029\n",
      "Episode: 715 Steps: 66 Total reward: 67.0 Training loss: 0.2282 Explore P: 0.0029\n",
      "Episode: 716 Steps: 198 Total reward: 199.0 Training loss: 0.2598 Explore P: 0.0028\n",
      "Episode: 717 Steps: 198 Total reward: 199.0 Training loss: 0.4586 Explore P: 0.0028\n",
      "Episode: 718 Steps: 198 Total reward: 199.0 Training loss: 0.9162 Explore P: 0.0027\n",
      "Episode: 719 Steps: 198 Total reward: 199.0 Training loss: 272.2663 Explore P: 0.0027\n",
      "Episode: 720 Steps: 198 Total reward: 199.0 Training loss: 1.8479 Explore P: 0.0027\n",
      "Episode: 721 Steps: 173 Total reward: 174.0 Training loss: 2.5251 Explore P: 0.0026\n",
      "Episode: 722 Steps: 12 Total reward: 13.0 Training loss: 1.9254 Explore P: 0.0026\n",
      "Episode: 723 Steps: 151 Total reward: 152.0 Training loss: 2.1605 Explore P: 0.0026\n",
      "Episode: 724 Steps: 145 Total reward: 146.0 Training loss: 462.7547 Explore P: 0.0026\n",
      "Episode: 725 Steps: 11 Total reward: 12.0 Training loss: 3.4479 Explore P: 0.0026\n",
      "Episode: 726 Steps: 10 Total reward: 11.0 Training loss: 3.0501 Explore P: 0.0026\n",
      "Episode: 727 Steps: 12 Total reward: 13.0 Training loss: 371.3864 Explore P: 0.0026\n",
      "Episode: 728 Steps: 9 Total reward: 10.0 Training loss: 458.6793 Explore P: 0.0026\n",
      "Episode: 729 Steps: 11 Total reward: 12.0 Training loss: 2.3025 Explore P: 0.0026\n",
      "Episode: 730 Steps: 8 Total reward: 9.0 Training loss: 2.4152 Explore P: 0.0026\n",
      "Episode: 731 Steps: 13 Total reward: 14.0 Training loss: 2.0983 Explore P: 0.0026\n",
      "Episode: 732 Steps: 13 Total reward: 14.0 Training loss: 2.6575 Explore P: 0.0026\n",
      "Episode: 733 Steps: 9 Total reward: 10.0 Training loss: 2.4398 Explore P: 0.0026\n",
      "Episode: 734 Steps: 14 Total reward: 15.0 Training loss: 1.9853 Explore P: 0.0026\n",
      "Episode: 735 Steps: 11 Total reward: 12.0 Training loss: 2.3285 Explore P: 0.0026\n",
      "Episode: 736 Steps: 10 Total reward: 11.0 Training loss: 2.7473 Explore P: 0.0026\n",
      "Episode: 737 Steps: 9 Total reward: 10.0 Training loss: 4.3219 Explore P: 0.0026\n",
      "Episode: 738 Steps: 12 Total reward: 13.0 Training loss: 1.6186 Explore P: 0.0026\n",
      "Episode: 739 Steps: 10 Total reward: 11.0 Training loss: 1.9088 Explore P: 0.0026\n",
      "Episode: 740 Steps: 14 Total reward: 15.0 Training loss: 2.1393 Explore P: 0.0026\n",
      "Episode: 741 Steps: 13 Total reward: 14.0 Training loss: 2.2161 Explore P: 0.0026\n",
      "Episode: 742 Steps: 12 Total reward: 13.0 Training loss: 418.0362 Explore P: 0.0026\n",
      "Episode: 743 Steps: 11 Total reward: 12.0 Training loss: 398.0050 Explore P: 0.0026\n",
      "Episode: 744 Steps: 14 Total reward: 15.0 Training loss: 2.6885 Explore P: 0.0026\n",
      "Episode: 745 Steps: 11 Total reward: 12.0 Training loss: 486.1358 Explore P: 0.0026\n",
      "Episode: 746 Steps: 13 Total reward: 14.0 Training loss: 1.7641 Explore P: 0.0026\n",
      "Episode: 747 Steps: 16 Total reward: 17.0 Training loss: 2.1594 Explore P: 0.0026\n",
      "Episode: 748 Steps: 12 Total reward: 13.0 Training loss: 2.2773 Explore P: 0.0025\n",
      "Episode: 749 Steps: 10 Total reward: 11.0 Training loss: 2.6139 Explore P: 0.0025\n",
      "Episode: 750 Steps: 13 Total reward: 14.0 Training loss: 2.6448 Explore P: 0.0025\n",
      "Episode: 751 Steps: 13 Total reward: 14.0 Training loss: 553.4030 Explore P: 0.0025\n",
      "Episode: 752 Steps: 10 Total reward: 11.0 Training loss: 2.9346 Explore P: 0.0025\n",
      "Episode: 753 Steps: 12 Total reward: 13.0 Training loss: 2.1715 Explore P: 0.0025\n",
      "Episode: 754 Steps: 11 Total reward: 12.0 Training loss: 2.9050 Explore P: 0.0025\n",
      "Episode: 755 Steps: 13 Total reward: 14.0 Training loss: 2.6047 Explore P: 0.0025\n",
      "Episode: 756 Steps: 11 Total reward: 12.0 Training loss: 2.4068 Explore P: 0.0025\n",
      "Episode: 757 Steps: 10 Total reward: 11.0 Training loss: 2.9724 Explore P: 0.0025\n",
      "Episode: 758 Steps: 12 Total reward: 13.0 Training loss: 3.0273 Explore P: 0.0025\n",
      "Episode: 759 Steps: 13 Total reward: 14.0 Training loss: 2.0215 Explore P: 0.0025\n",
      "Episode: 760 Steps: 14 Total reward: 15.0 Training loss: 578.5297 Explore P: 0.0025\n",
      "Episode: 761 Steps: 15 Total reward: 16.0 Training loss: 2.2291 Explore P: 0.0025\n",
      "Episode: 762 Steps: 12 Total reward: 13.0 Training loss: 2.1473 Explore P: 0.0025\n",
      "Episode: 763 Steps: 154 Total reward: 155.0 Training loss: 3.1283 Explore P: 0.0025\n",
      "Episode: 764 Steps: 14 Total reward: 15.0 Training loss: 2.1193 Explore P: 0.0025\n",
      "Episode: 765 Steps: 133 Total reward: 134.0 Training loss: 2.8465 Explore P: 0.0025\n",
      "Episode: 766 Steps: 198 Total reward: 199.0 Training loss: 493.4096 Explore P: 0.0024\n",
      "Episode: 767 Steps: 198 Total reward: 199.0 Training loss: 1.8824 Explore P: 0.0024\n",
      "Episode: 768 Steps: 198 Total reward: 199.0 Training loss: 1.5618 Explore P: 0.0024\n",
      "Episode: 769 Steps: 198 Total reward: 199.0 Training loss: 0.9992 Explore P: 0.0024\n",
      "Episode: 770 Steps: 198 Total reward: 199.0 Training loss: 227.8978 Explore P: 0.0023\n",
      "Episode: 771 Steps: 198 Total reward: 199.0 Training loss: 1.2174 Explore P: 0.0023\n",
      "Episode: 772 Steps: 198 Total reward: 199.0 Training loss: 417.3080 Explore P: 0.0023\n",
      "Episode: 773 Steps: 198 Total reward: 199.0 Training loss: 170.3351 Explore P: 0.0023\n",
      "Episode: 774 Steps: 198 Total reward: 199.0 Training loss: 173.3561 Explore P: 0.0022\n",
      "Episode: 775 Steps: 198 Total reward: 199.0 Training loss: 1.2671 Explore P: 0.0022\n",
      "Episode: 776 Steps: 198 Total reward: 199.0 Training loss: 0.9557 Explore P: 0.0022\n",
      "Episode: 777 Steps: 198 Total reward: 199.0 Training loss: 1.0882 Explore P: 0.0022\n",
      "Episode: 778 Steps: 198 Total reward: 199.0 Training loss: 1.8674 Explore P: 0.0021\n",
      "Episode: 779 Steps: 198 Total reward: 199.0 Training loss: 1.8004 Explore P: 0.0021\n",
      "Episode: 780 Steps: 198 Total reward: 199.0 Training loss: 2.2590 Explore P: 0.0021\n",
      "Episode: 781 Steps: 198 Total reward: 199.0 Training loss: 321.8111 Explore P: 0.0021\n",
      "Episode: 782 Steps: 198 Total reward: 199.0 Training loss: 185.0773 Explore P: 0.0021\n",
      "Episode: 783 Steps: 198 Total reward: 199.0 Training loss: 2.1982 Explore P: 0.0020\n",
      "Episode: 784 Steps: 198 Total reward: 199.0 Training loss: 2.1939 Explore P: 0.0020\n",
      "Episode: 785 Steps: 198 Total reward: 199.0 Training loss: 209.9314 Explore P: 0.0020\n",
      "Episode: 786 Steps: 198 Total reward: 199.0 Training loss: 2.8916 Explore P: 0.0020\n",
      "Episode: 787 Steps: 198 Total reward: 199.0 Training loss: 1.1419 Explore P: 0.0020\n",
      "Episode: 788 Steps: 198 Total reward: 199.0 Training loss: 6.0486 Explore P: 0.0019\n",
      "Episode: 789 Steps: 198 Total reward: 199.0 Training loss: 2.7624 Explore P: 0.0019\n",
      "Episode: 790 Steps: 198 Total reward: 199.0 Training loss: 3.9498 Explore P: 0.0019\n",
      "Episode: 791 Steps: 198 Total reward: 199.0 Training loss: 166.7610 Explore P: 0.0019\n",
      "Episode: 792 Steps: 198 Total reward: 199.0 Training loss: 1.3422 Explore P: 0.0019\n",
      "Episode: 793 Steps: 198 Total reward: 199.0 Training loss: 215.2909 Explore P: 0.0018\n",
      "Episode: 794 Steps: 198 Total reward: 199.0 Training loss: 1.4033 Explore P: 0.0018\n",
      "Episode: 795 Steps: 198 Total reward: 199.0 Training loss: 5.7363 Explore P: 0.0018\n",
      "Episode: 796 Steps: 198 Total reward: 199.0 Training loss: 3.7522 Explore P: 0.0018\n",
      "Episode: 797 Steps: 198 Total reward: 199.0 Training loss: 6.6887 Explore P: 0.0018\n",
      "Episode: 798 Steps: 198 Total reward: 199.0 Training loss: 286.9583 Explore P: 0.0018\n",
      "Episode: 799 Steps: 198 Total reward: 199.0 Training loss: 2.5112 Explore P: 0.0018\n",
      "Episode: 800 Steps: 198 Total reward: 199.0 Training loss: 3.0874 Explore P: 0.0017\n",
      "Episode: 801 Steps: 198 Total reward: 199.0 Training loss: 8.5891 Explore P: 0.0017\n",
      "Episode: 802 Steps: 198 Total reward: 199.0 Training loss: 1.5592 Explore P: 0.0017\n",
      "Episode: 803 Steps: 198 Total reward: 199.0 Training loss: 6.0952 Explore P: 0.0017\n",
      "Episode: 804 Steps: 198 Total reward: 199.0 Training loss: 1.1627 Explore P: 0.0017\n",
      "Episode: 805 Steps: 198 Total reward: 199.0 Training loss: 3.8227 Explore P: 0.0017\n",
      "Episode: 806 Steps: 198 Total reward: 199.0 Training loss: 1.6068 Explore P: 0.0017\n",
      "Episode: 807 Steps: 198 Total reward: 199.0 Training loss: 3.5886 Explore P: 0.0016\n",
      "Episode: 808 Steps: 198 Total reward: 199.0 Training loss: 3.7695 Explore P: 0.0016\n",
      "Episode: 809 Steps: 198 Total reward: 199.0 Training loss: 15.3796 Explore P: 0.0016\n",
      "Episode: 810 Steps: 11 Total reward: 12.0 Training loss: 9.6037 Explore P: 0.0016\n",
      "Episode: 811 Steps: 8 Total reward: 9.0 Training loss: 15.3537 Explore P: 0.0016\n",
      "Episode: 812 Steps: 9 Total reward: 10.0 Training loss: 175.0901 Explore P: 0.0016\n",
      "Episode: 813 Steps: 7 Total reward: 8.0 Training loss: 9.6174 Explore P: 0.0016\n",
      "Episode: 814 Steps: 7 Total reward: 8.0 Training loss: 9.8268 Explore P: 0.0016\n",
      "Episode: 815 Steps: 7 Total reward: 8.0 Training loss: 49.3867 Explore P: 0.0016\n",
      "Episode: 816 Steps: 11 Total reward: 12.0 Training loss: 19.9746 Explore P: 0.0016\n",
      "Episode: 817 Steps: 8 Total reward: 9.0 Training loss: 15.2322 Explore P: 0.0016\n",
      "Episode: 818 Steps: 11 Total reward: 12.0 Training loss: 14.4020 Explore P: 0.0016\n",
      "Episode: 819 Steps: 10 Total reward: 11.0 Training loss: 27.4519 Explore P: 0.0016\n",
      "Episode: 820 Steps: 9 Total reward: 10.0 Training loss: 24.6594 Explore P: 0.0016\n",
      "Episode: 821 Steps: 6 Total reward: 7.0 Training loss: 18.2088 Explore P: 0.0016\n",
      "Episode: 822 Steps: 8 Total reward: 9.0 Training loss: 32.1221 Explore P: 0.0016\n",
      "Episode: 823 Steps: 6 Total reward: 7.0 Training loss: 30.0146 Explore P: 0.0016\n",
      "Episode: 824 Steps: 8 Total reward: 9.0 Training loss: 23.2675 Explore P: 0.0016\n",
      "Episode: 825 Steps: 11 Total reward: 12.0 Training loss: 37.2830 Explore P: 0.0016\n",
      "Episode: 826 Steps: 9 Total reward: 10.0 Training loss: 240.1817 Explore P: 0.0016\n",
      "Episode: 827 Steps: 9 Total reward: 10.0 Training loss: 25.6591 Explore P: 0.0016\n",
      "Episode: 828 Steps: 7 Total reward: 8.0 Training loss: 53.4305 Explore P: 0.0016\n",
      "Episode: 829 Steps: 10 Total reward: 11.0 Training loss: 40.3167 Explore P: 0.0016\n",
      "Episode: 830 Steps: 10 Total reward: 11.0 Training loss: 49.6625 Explore P: 0.0016\n",
      "Episode: 831 Steps: 8 Total reward: 9.0 Training loss: 30.9959 Explore P: 0.0016\n",
      "Episode: 832 Steps: 7 Total reward: 8.0 Training loss: 24.5262 Explore P: 0.0016\n",
      "Episode: 833 Steps: 7 Total reward: 8.0 Training loss: 53.1178 Explore P: 0.0016\n",
      "Episode: 834 Steps: 10 Total reward: 11.0 Training loss: 28.0623 Explore P: 0.0016\n",
      "Episode: 835 Steps: 8 Total reward: 9.0 Training loss: 63.6335 Explore P: 0.0016\n",
      "Episode: 836 Steps: 10 Total reward: 11.0 Training loss: 2494.3533 Explore P: 0.0016\n",
      "Episode: 837 Steps: 8 Total reward: 9.0 Training loss: 57.6768 Explore P: 0.0016\n",
      "Episode: 838 Steps: 8 Total reward: 9.0 Training loss: 42.0270 Explore P: 0.0016\n",
      "Episode: 839 Steps: 10 Total reward: 11.0 Training loss: 25.0760 Explore P: 0.0016\n",
      "Episode: 840 Steps: 6 Total reward: 7.0 Training loss: 40.4888 Explore P: 0.0016\n",
      "Episode: 841 Steps: 10 Total reward: 11.0 Training loss: 30.1748 Explore P: 0.0016\n",
      "Episode: 842 Steps: 11 Total reward: 12.0 Training loss: 42.7452 Explore P: 0.0016\n",
      "Episode: 843 Steps: 7 Total reward: 8.0 Training loss: 2326.1199 Explore P: 0.0016\n",
      "Episode: 844 Steps: 8 Total reward: 9.0 Training loss: 834.8706 Explore P: 0.0016\n",
      "Episode: 845 Steps: 10 Total reward: 11.0 Training loss: 42.7985 Explore P: 0.0016\n",
      "Episode: 846 Steps: 6 Total reward: 7.0 Training loss: 984.4062 Explore P: 0.0016\n",
      "Episode: 847 Steps: 8 Total reward: 9.0 Training loss: 26.3680 Explore P: 0.0016\n",
      "Episode: 848 Steps: 7 Total reward: 8.0 Training loss: 513.6233 Explore P: 0.0016\n",
      "Episode: 849 Steps: 10 Total reward: 11.0 Training loss: 34.3364 Explore P: 0.0016\n",
      "Episode: 850 Steps: 9 Total reward: 10.0 Training loss: 28.6520 Explore P: 0.0016\n",
      "Episode: 851 Steps: 10 Total reward: 11.0 Training loss: 41.6004 Explore P: 0.0016\n",
      "Episode: 852 Steps: 7 Total reward: 8.0 Training loss: 24.2041 Explore P: 0.0016\n",
      "Episode: 853 Steps: 9 Total reward: 10.0 Training loss: 28.3643 Explore P: 0.0016\n",
      "Episode: 854 Steps: 8 Total reward: 9.0 Training loss: 22.8537 Explore P: 0.0016\n",
      "Episode: 855 Steps: 8 Total reward: 9.0 Training loss: 11.5631 Explore P: 0.0016\n",
      "Episode: 856 Steps: 9 Total reward: 10.0 Training loss: 737.2981 Explore P: 0.0016\n",
      "Episode: 857 Steps: 10 Total reward: 11.0 Training loss: 18.8553 Explore P: 0.0016\n",
      "Episode: 858 Steps: 8 Total reward: 9.0 Training loss: 689.9839 Explore P: 0.0016\n",
      "Episode: 859 Steps: 12 Total reward: 13.0 Training loss: 1725.3962 Explore P: 0.0016\n",
      "Episode: 860 Steps: 9 Total reward: 10.0 Training loss: 16.2327 Explore P: 0.0016\n",
      "Episode: 861 Steps: 11 Total reward: 12.0 Training loss: 1438.5934 Explore P: 0.0016\n",
      "Episode: 862 Steps: 8 Total reward: 9.0 Training loss: 13.1388 Explore P: 0.0016\n",
      "Episode: 863 Steps: 9 Total reward: 10.0 Training loss: 852.6414 Explore P: 0.0016\n",
      "Episode: 864 Steps: 10 Total reward: 11.0 Training loss: 20.2718 Explore P: 0.0016\n",
      "Episode: 865 Steps: 9 Total reward: 10.0 Training loss: 16.8832 Explore P: 0.0016\n",
      "Episode: 866 Steps: 10 Total reward: 11.0 Training loss: 11.2566 Explore P: 0.0016\n",
      "Episode: 867 Steps: 9 Total reward: 10.0 Training loss: 14.7683 Explore P: 0.0016\n",
      "Episode: 868 Steps: 8 Total reward: 9.0 Training loss: 10.9238 Explore P: 0.0016\n",
      "Episode: 869 Steps: 12 Total reward: 13.0 Training loss: 1577.5826 Explore P: 0.0016\n",
      "Episode: 870 Steps: 12 Total reward: 13.0 Training loss: 6.5440 Explore P: 0.0016\n",
      "Episode: 871 Steps: 8 Total reward: 9.0 Training loss: 16.3990 Explore P: 0.0016\n",
      "Episode: 872 Steps: 11 Total reward: 12.0 Training loss: 7.0579 Explore P: 0.0016\n",
      "Episode: 873 Steps: 12 Total reward: 13.0 Training loss: 21.2239 Explore P: 0.0016\n",
      "Episode: 874 Steps: 12 Total reward: 13.0 Training loss: 12.6883 Explore P: 0.0016\n",
      "Episode: 875 Steps: 10 Total reward: 11.0 Training loss: 11.4717 Explore P: 0.0016\n",
      "Episode: 876 Steps: 7 Total reward: 8.0 Training loss: 15.4409 Explore P: 0.0016\n",
      "Episode: 877 Steps: 9 Total reward: 10.0 Training loss: 20.4678 Explore P: 0.0016\n",
      "Episode: 878 Steps: 12 Total reward: 13.0 Training loss: 13.4625 Explore P: 0.0016\n",
      "Episode: 879 Steps: 9 Total reward: 10.0 Training loss: 8.7481 Explore P: 0.0016\n",
      "Episode: 880 Steps: 10 Total reward: 11.0 Training loss: 795.4213 Explore P: 0.0016\n",
      "Episode: 881 Steps: 13 Total reward: 14.0 Training loss: 8.8147 Explore P: 0.0016\n",
      "Episode: 882 Steps: 13 Total reward: 14.0 Training loss: 1505.0869 Explore P: 0.0016\n",
      "Episode: 883 Steps: 11 Total reward: 12.0 Training loss: 5.2569 Explore P: 0.0016\n",
      "Episode: 884 Steps: 11 Total reward: 12.0 Training loss: 980.7355 Explore P: 0.0016\n",
      "Episode: 885 Steps: 12 Total reward: 13.0 Training loss: 8.9135 Explore P: 0.0016\n",
      "Episode: 886 Steps: 14 Total reward: 15.0 Training loss: 452.0023 Explore P: 0.0016\n",
      "Episode: 887 Steps: 13 Total reward: 14.0 Training loss: 14.4050 Explore P: 0.0016\n",
      "Episode: 888 Steps: 14 Total reward: 15.0 Training loss: 13.8855 Explore P: 0.0016\n",
      "Episode: 889 Steps: 13 Total reward: 14.0 Training loss: 8.7160 Explore P: 0.0016\n",
      "Episode: 890 Steps: 15 Total reward: 16.0 Training loss: 6.2128 Explore P: 0.0016\n",
      "Episode: 891 Steps: 65 Total reward: 66.0 Training loss: 7.4474 Explore P: 0.0016\n",
      "Episode: 892 Steps: 198 Total reward: 199.0 Training loss: 9.3421 Explore P: 0.0016\n",
      "Episode: 893 Steps: 198 Total reward: 199.0 Training loss: 3.0974 Explore P: 0.0015\n",
      "Episode: 894 Steps: 198 Total reward: 199.0 Training loss: 2.8788 Explore P: 0.0015\n",
      "Episode: 895 Steps: 198 Total reward: 199.0 Training loss: 12.3415 Explore P: 0.0015\n",
      "Episode: 896 Steps: 146 Total reward: 147.0 Training loss: 588.0980 Explore P: 0.0015\n",
      "Episode: 897 Steps: 155 Total reward: 156.0 Training loss: 6.9722 Explore P: 0.0015\n",
      "Episode: 898 Steps: 126 Total reward: 127.0 Training loss: 8.0468 Explore P: 0.0015\n",
      "Episode: 899 Steps: 148 Total reward: 149.0 Training loss: 5.9625 Explore P: 0.0015\n",
      "Episode: 900 Steps: 137 Total reward: 138.0 Training loss: 8.3054 Explore P: 0.0015\n",
      "Episode: 901 Steps: 119 Total reward: 120.0 Training loss: 105.0307 Explore P: 0.0015\n",
      "Episode: 902 Steps: 17 Total reward: 18.0 Training loss: 15.5176 Explore P: 0.0015\n",
      "Episode: 903 Steps: 20 Total reward: 21.0 Training loss: 11.3152 Explore P: 0.0015\n",
      "Episode: 904 Steps: 104 Total reward: 105.0 Training loss: 8.8192 Explore P: 0.0015\n",
      "Episode: 905 Steps: 132 Total reward: 133.0 Training loss: 22.8540 Explore P: 0.0015\n",
      "Episode: 906 Steps: 114 Total reward: 115.0 Training loss: 8.9471 Explore P: 0.0015\n",
      "Episode: 907 Steps: 18 Total reward: 19.0 Training loss: 338.4163 Explore P: 0.0015\n",
      "Episode: 908 Steps: 20 Total reward: 21.0 Training loss: 10.7344 Explore P: 0.0015\n",
      "Episode: 909 Steps: 15 Total reward: 16.0 Training loss: 4.7940 Explore P: 0.0015\n",
      "Episode: 910 Steps: 100 Total reward: 101.0 Training loss: 11.5812 Explore P: 0.0015\n",
      "Episode: 911 Steps: 17 Total reward: 18.0 Training loss: 7.1606 Explore P: 0.0015\n",
      "Episode: 912 Steps: 18 Total reward: 19.0 Training loss: 3024.7832 Explore P: 0.0014\n",
      "Episode: 913 Steps: 16 Total reward: 17.0 Training loss: 77.2562 Explore P: 0.0014\n",
      "Episode: 914 Steps: 20 Total reward: 21.0 Training loss: 9.1977 Explore P: 0.0014\n",
      "Episode: 915 Steps: 20 Total reward: 21.0 Training loss: 6.2356 Explore P: 0.0014\n",
      "Episode: 916 Steps: 19 Total reward: 20.0 Training loss: 8.9568 Explore P: 0.0014\n",
      "Episode: 917 Steps: 17 Total reward: 18.0 Training loss: 21.1792 Explore P: 0.0014\n",
      "Episode: 918 Steps: 18 Total reward: 19.0 Training loss: 12.5087 Explore P: 0.0014\n",
      "Episode: 919 Steps: 16 Total reward: 17.0 Training loss: 7.2330 Explore P: 0.0014\n",
      "Episode: 920 Steps: 15 Total reward: 16.0 Training loss: 637.8126 Explore P: 0.0014\n",
      "Episode: 921 Steps: 14 Total reward: 15.0 Training loss: 98.2978 Explore P: 0.0014\n",
      "Episode: 922 Steps: 19 Total reward: 20.0 Training loss: 7.8193 Explore P: 0.0014\n",
      "Episode: 923 Steps: 18 Total reward: 19.0 Training loss: 18.6949 Explore P: 0.0014\n",
      "Episode: 924 Steps: 20 Total reward: 21.0 Training loss: 8.3217 Explore P: 0.0014\n",
      "Episode: 925 Steps: 18 Total reward: 19.0 Training loss: 10.3320 Explore P: 0.0014\n",
      "Episode: 926 Steps: 16 Total reward: 17.0 Training loss: 26.2794 Explore P: 0.0014\n",
      "Episode: 927 Steps: 13 Total reward: 14.0 Training loss: 10.9278 Explore P: 0.0014\n",
      "Episode: 928 Steps: 13 Total reward: 14.0 Training loss: 9.9649 Explore P: 0.0014\n",
      "Episode: 929 Steps: 13 Total reward: 14.0 Training loss: 17.1772 Explore P: 0.0014\n",
      "Episode: 930 Steps: 12 Total reward: 13.0 Training loss: 599.0474 Explore P: 0.0014\n",
      "Episode: 931 Steps: 18 Total reward: 19.0 Training loss: 15.4633 Explore P: 0.0014\n",
      "Episode: 932 Steps: 18 Total reward: 19.0 Training loss: 8.0860 Explore P: 0.0014\n",
      "Episode: 933 Steps: 17 Total reward: 18.0 Training loss: 9.6735 Explore P: 0.0014\n",
      "Episode: 934 Steps: 21 Total reward: 22.0 Training loss: 6.5687 Explore P: 0.0014\n",
      "Episode: 935 Steps: 20 Total reward: 21.0 Training loss: 10.6765 Explore P: 0.0014\n",
      "Episode: 936 Steps: 18 Total reward: 19.0 Training loss: 12.3598 Explore P: 0.0014\n",
      "Episode: 937 Steps: 14 Total reward: 15.0 Training loss: 1489.5668 Explore P: 0.0014\n",
      "Episode: 938 Steps: 17 Total reward: 18.0 Training loss: 679.2871 Explore P: 0.0014\n",
      "Episode: 939 Steps: 18 Total reward: 19.0 Training loss: 13.5631 Explore P: 0.0014\n",
      "Episode: 940 Steps: 22 Total reward: 23.0 Training loss: 9.9284 Explore P: 0.0014\n",
      "Episode: 941 Steps: 21 Total reward: 22.0 Training loss: 9.3459 Explore P: 0.0014\n",
      "Episode: 942 Steps: 111 Total reward: 112.0 Training loss: 5.4932 Explore P: 0.0014\n",
      "Episode: 943 Steps: 132 Total reward: 133.0 Training loss: 10.6637 Explore P: 0.0014\n",
      "Episode: 944 Steps: 17 Total reward: 18.0 Training loss: 462.5894 Explore P: 0.0014\n",
      "Episode: 945 Steps: 22 Total reward: 23.0 Training loss: 8.2447 Explore P: 0.0014\n",
      "Episode: 946 Steps: 114 Total reward: 115.0 Training loss: 1154.0288 Explore P: 0.0014\n",
      "Episode: 947 Steps: 121 Total reward: 122.0 Training loss: 7.1843 Explore P: 0.0014\n",
      "Episode: 948 Steps: 120 Total reward: 121.0 Training loss: 741.8691 Explore P: 0.0014\n",
      "Episode: 949 Steps: 147 Total reward: 148.0 Training loss: 12.0581 Explore P: 0.0014\n",
      "Episode: 950 Steps: 127 Total reward: 128.0 Training loss: 143.3741 Explore P: 0.0014\n",
      "Episode: 951 Steps: 158 Total reward: 159.0 Training loss: 14.8511 Explore P: 0.0014\n",
      "Episode: 952 Steps: 28 Total reward: 29.0 Training loss: 3222.2617 Explore P: 0.0014\n",
      "Episode: 953 Steps: 179 Total reward: 180.0 Training loss: 11.0224 Explore P: 0.0014\n",
      "Episode: 954 Steps: 158 Total reward: 159.0 Training loss: 9.7517 Explore P: 0.0014\n",
      "Episode: 955 Steps: 198 Total reward: 199.0 Training loss: 12.0696 Explore P: 0.0014\n",
      "Episode: 956 Steps: 165 Total reward: 166.0 Training loss: 429.1118 Explore P: 0.0014\n",
      "Episode: 957 Steps: 179 Total reward: 180.0 Training loss: 664.4956 Explore P: 0.0013\n",
      "Episode: 958 Steps: 171 Total reward: 172.0 Training loss: 14.2246 Explore P: 0.0013\n",
      "Episode: 959 Steps: 198 Total reward: 199.0 Training loss: 13.9268 Explore P: 0.0013\n",
      "Episode: 960 Steps: 179 Total reward: 180.0 Training loss: 16.3536 Explore P: 0.0013\n",
      "Episode: 961 Steps: 183 Total reward: 184.0 Training loss: 10.0465 Explore P: 0.0013\n",
      "Episode: 962 Steps: 182 Total reward: 183.0 Training loss: 15.2031 Explore P: 0.0013\n",
      "Episode: 963 Steps: 198 Total reward: 199.0 Training loss: 12.7518 Explore P: 0.0013\n",
      "Episode: 964 Steps: 198 Total reward: 199.0 Training loss: 14.0092 Explore P: 0.0013\n",
      "Episode: 965 Steps: 198 Total reward: 199.0 Training loss: 615.2549 Explore P: 0.0013\n",
      "Episode: 966 Steps: 198 Total reward: 199.0 Training loss: 581.0882 Explore P: 0.0013\n",
      "Episode: 967 Steps: 198 Total reward: 199.0 Training loss: 6.8612 Explore P: 0.0013\n",
      "Episode: 968 Steps: 198 Total reward: 199.0 Training loss: 8.8638 Explore P: 0.0013\n",
      "Episode: 969 Steps: 198 Total reward: 199.0 Training loss: 11.0165 Explore P: 0.0013\n",
      "Episode: 970 Steps: 198 Total reward: 199.0 Training loss: 10.1932 Explore P: 0.0013\n",
      "Episode: 971 Steps: 198 Total reward: 199.0 Training loss: 7.0461 Explore P: 0.0013\n",
      "Episode: 972 Steps: 198 Total reward: 199.0 Training loss: 7.3127 Explore P: 0.0013\n",
      "Episode: 973 Steps: 198 Total reward: 199.0 Training loss: 308.4316 Explore P: 0.0013\n",
      "Episode: 974 Steps: 198 Total reward: 199.0 Training loss: 230.5011 Explore P: 0.0013\n",
      "Episode: 975 Steps: 198 Total reward: 199.0 Training loss: 48.2373 Explore P: 0.0012\n",
      "Episode: 976 Steps: 198 Total reward: 199.0 Training loss: 21.2133 Explore P: 0.0012\n",
      "Episode: 977 Steps: 198 Total reward: 199.0 Training loss: 4.3882 Explore P: 0.0012\n",
      "Episode: 978 Steps: 198 Total reward: 199.0 Training loss: 376.9711 Explore P: 0.0012\n",
      "Episode: 979 Steps: 198 Total reward: 199.0 Training loss: 6.5402 Explore P: 0.0012\n",
      "Episode: 980 Steps: 198 Total reward: 199.0 Training loss: 3.4652 Explore P: 0.0012\n",
      "Episode: 981 Steps: 198 Total reward: 199.0 Training loss: 3.4976 Explore P: 0.0012\n",
      "Episode: 982 Steps: 198 Total reward: 199.0 Training loss: 2.5696 Explore P: 0.0012\n",
      "Episode: 983 Steps: 198 Total reward: 199.0 Training loss: 1.5938 Explore P: 0.0012\n",
      "Episode: 984 Steps: 198 Total reward: 199.0 Training loss: 2.0051 Explore P: 0.0012\n",
      "Episode: 985 Steps: 198 Total reward: 199.0 Training loss: 2.4153 Explore P: 0.0012\n",
      "Episode: 986 Steps: 198 Total reward: 199.0 Training loss: 1.5858 Explore P: 0.0012\n",
      "Episode: 987 Steps: 198 Total reward: 199.0 Training loss: 1.2971 Explore P: 0.0012\n",
      "Episode: 988 Steps: 198 Total reward: 199.0 Training loss: 1.4956 Explore P: 0.0012\n",
      "Episode: 989 Steps: 198 Total reward: 199.0 Training loss: 2.7946 Explore P: 0.0012\n",
      "Episode: 990 Steps: 198 Total reward: 199.0 Training loss: 1.7944 Explore P: 0.0012\n",
      "Episode: 991 Steps: 198 Total reward: 199.0 Training loss: 2.2312 Explore P: 0.0012\n",
      "Episode: 992 Steps: 198 Total reward: 199.0 Training loss: 1.5387 Explore P: 0.0012\n",
      "Episode: 993 Steps: 198 Total reward: 199.0 Training loss: 1.7385 Explore P: 0.0012\n",
      "Episode: 994 Steps: 198 Total reward: 199.0 Training loss: 1.5638 Explore P: 0.0012\n",
      "Episode: 995 Steps: 198 Total reward: 199.0 Training loss: 1.5958 Explore P: 0.0012\n",
      "Episode: 996 Steps: 198 Total reward: 199.0 Training loss: 1.4497 Explore P: 0.0012\n",
      "Episode: 997 Steps: 198 Total reward: 199.0 Training loss: 1.4277 Explore P: 0.0012\n",
      "Episode: 998 Steps: 198 Total reward: 199.0 Training loss: 0.9734 Explore P: 0.0012\n",
      "Episode: 999 Steps: 198 Total reward: 199.0 Training loss: 1.0019 Explore P: 0.0012\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            # print(t)\n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                #t = max_steps\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Steps: {}'.format(t),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "                \n",
    "                #exit loop\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "        \n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12062f7b8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng8TMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114745710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_episodes = 10\n",
    "test_max_steps = 400\n",
    "env.reset()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    for ep in range(1, test_episodes):\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            env.render() \n",
    "            \n",
    "            # Get action from Q-network\n",
    "            feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "            Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "            action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}